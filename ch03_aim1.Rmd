---
documentclass: apa6
classoption: "margin=1in,man,floatsintext"
header-includes:
  # - \usepackage[para,online,flushleft]{threeparttable}
  - \usepackage{wrapfig}
  - \usepackage[singlelinecheck=false]{caption}
  - \captionsetup[subfigure]{singlelinecheck=on, labelfont=normalfont}
  - \captionsetup[figure]{labelfont=it}
  - \shorttitle{SOCIAL MOTIVES \& REINFORCEMENT LEARNING}
title: "Social motive effects on reinforcement learning"
author: "John C. Flournoy"
output: 
  pdf_document:
    keep_tex: yes
    template: "default-1.17.0.2_nogeom.tex"
bibliography: "/home/jflournoy/code_new/social-motives-rl-writeup/dissertation.bib"
csl: "/home/jflournoy/Rlibs/probly/bib/apa-old-doi-prefix.csl"
---

```{r setupch3, include=FALSE}
knitr::opts_chunk$set(fig.path = 'figures/', echo = F, warning = F, error = F, message = F)
library(probly)
load('rda/descriptive-statistics.rda')
load('rda/test-simulated-data.rda')

ptab <- Hmisc::latex

ethnicity_labels <- c(
    'American Indian and Alaska Native' = 'AmIndn',
    'Asian' = 'Asian',
    'Black or African American' = 'Black/AA',
    'Latinx/Hispanic' = 'Latinx/Hsp',
    'Native Hawaiian and Other Pacific Islander' = 'Pcfc Islnd',
    'Other' = 'Other',
    'White' = 'White',
    'White/Hispanic' = 'Wht/Hsp'
)
ethnicity_abbreviation_note <- paste0(paste(paste0(ethnicity_labels, ': ', names(ethnicity_labels)), collapse = '; '), '.')

sample_abbreviation_note <- 'FCA: foster-care-involved adolescents; CA: community adolescents; CSYA: college students; CSYA-O: college students, online.'
```

```{r}
library(tables)
mean.na.rm <- function(x){mean(as.numeric(x), na.rm=T)}
sd.na.rm <- function(x){sd(x, na.rm=T)}
nmissing <- function(x){m <- sum(is.na(x));ifelse(m==0,'-',m)}
prct_missing <- function(x,y){pct <- 100*sum(is.na(x))/length(y);ifelse(pct==0,'\\-',pct)}
minmax.na.rm <- function(x){sprintf('[%0.0f,%0.0f]',round(min(x, na.rm = T),0), round(max(x, na.rm = T),0))}

splt_dev_and_demog_task_sum$sample <- 
    factor(splt_dev_and_demog_task_sum$sample, 
           levels = c("Foster-care involved adolescents", 
                      "Community adolescents", 
                      "College students", 
                      "College students - online"), 
           labels = c('FCA', 'CA', 'CSYA', 'CSYA-O'))

splt_summary_optimal_feedback$sample <- 
    factor(splt_summary_optimal_feedback$sample, 
           levels = c("Foster-care involved adolescents", 
                      "Community adolescents", 
                      "College students", 
                      "College students - online"), 
           labels = c('FCA', 'CA', 'CSYA', 'CSYA-O'))

sample_table <- tables::tabular(
    (Sample=sample) ~ 
        (N = 1)*Heading()*(gender) +
        (Format(digits=2)*(Age = age) + 
             Format(digits=1)*(PDS = PDS_mean_score))*Heading()*(gender)*
                  ((M = mean.na.rm) + 
                       (`SD` = sd.na.rm)), 
    data = splt_dev_and_demog_task_sum)

trials_table <- tables::tabular(
    (Sample=sample) ~ 
        (Format(digits=0)*(`$N_{\\text{trials}}$` = ntrials))*Heading()*(gender)*
                  ((M = mean.na.rm) + 
                       (`SD` = sd.na.rm)), 
    data = splt_dev_and_demog_task_sum)

missing_table <- tables::tabular(
    ((Sample=sample) + 1) ~ 
        (N=1) +
             (((Age=age) + (PDS=PDS_mean_score) + (Gender = gender_num) + (Task = ntrials))*
                  ((`$N_{\\text{miss}}$` = nmissing) + Format(digits=1)*(`\\%` = Percent(fn = prct_missing)))), 
    data = splt_dev_and_demog_task_sum)

optimal_press_prop_table <- tables::tabular((Condition = condition)*(Sample = sample) ~ 
                    Heading('Probability of reward')*
                    identity*Heading()*Format(digits=3)*p_optimal_correct, 
                data = splt_summary_optimal_feedback)
ethnicity_table <- tables::tabular(
    Heading('Percent (\\%)')*ethnicity*Heading()*Format(digits=1)*Percent(denom = 'col') ~
        1 + Heading()*(Sample = sample),
    data = splt_dev_and_demog_task_sum)
```


# Background

Adolescence is a time of social reorientation during which individuals begin expressing romantic and sexual interests [for an overview, see: @collins2003; @collins2009], and spend more time with peers [at least, relative to time spent with family; @larson1991;@larson1996;@richards1998].
The social reorientation hypothesis in developmental cognitive neuroscience proposes that these changes are the result of developing motivations that shift goals toward increasing social experiences in peer and romantic social networks [@nelson2005;@nelson2016].
It further proposes that neurodevelopmental changes in perceptual, motivational, and executive control brain regions are the mechanisms that cause transitions through sensitive periods in development in which these systems are tuned to relevant social experiences (both in the sense of being receptive to, and motivated toward them).

The identification of period-relevant social goals mirrors work in evolutionary psychology that has lead to a taxonomy of social motives which are broadly anchored by evolutionarily important social relationships [e.g., caregivers, peers, potential mates, mates, and offspring; for a thorough overview, see @neel2015].
This work identifies social status and mate-seeking as distinct social motives that are not merely aspects of (a perhaps earlier-developing) affiliation motive, and provides a complimentary framework for thinking about the distinct fitness challenges adolescents begin to face as they transition beyond the juvenile period.
The development of these social motives, and their role in learning and decision making, is important to understand given their likely contribution to many types of decision making and, as suggested by @nelson2016, to psychopathology.

One implication of the reorientation thought to arise from changes in social motives is that there should be concomitant changes in the value and salience of motive-relevant stimuli.
While it may be the case that pubertally triggered neurobiological changes begin to directly alter the salience of cues that are evolutionarily stable predictors of period-relevant rewards, it is also probably the case that environmentally constrained changes in reward contingencies also alter the value of certain cues.
In other words, changes in stimulus-salience may arise from feedback between the congenital changes in the salience of particular stimuli, and learning that links those stimuli to particular outcomes.
In adolescence, specifically, this should result in increases in the salience of stimuli relevant to the milieux of the peer group and of potential romantic partners (for example, stimuli related to social status, and dating availability, respectively). 

## Salience and learning

The reciprocal relation between stimulus salience, motivation, and learning is an important foundation for the idea that developmental changes in motivational systems should be responsible, in part, for the social reorientation thought to occur during adolescence. 
A substantial body of work on learning and attention has shown that more salient cues enhance learning, and that learned predictive value modifies cue salience.
In laying out a programmatic approach to learning and attention, @mackintosh1975 states learning rates are different depending on the stimulus because the "probability of attending to a stimulus determines the probability of learning about that stimulus" (p. 294).
@grossberg1975 summarizes a body of literature indicating that if two cues are paired with an unconditioned stimulus, the more salient cue will be conditioned more quickly, even to the extent that it may block the conditioning of the less salient cue.

Cue salience can both modulate, and be modulated by, blocking effects.
For example, using cues of colored dots and modulating salience by the density of dots, @denton2006 showed that it is harder to block a new cue if that new cue is more salient (i.e., has higher dot density) than the already conditioned cue.
In other blocking paradigms, learning an association between a highly predictive cue and outcome blocks an organisms ability to form an association between that outcome and a new cue that is paired with the initially learned cue [see @shanks2010 for an overview].
This has been interpreted as indicating that the "blocked" stimulus essentially becomes less salient than the initially learned stimulus.
Though many models have been developed to account for this phenomenon, one explanation is that the new stimulus provides no new information for predicting the outcome (which is already perfectly predicted by the prior associated stimulus).

From an evolutionary perspective, the modulation of learning by salience, and salience by learning, is harmonious with both the idea that the environment is not perfectly stable, as well as with the idea that the goals, social or otherwise, of an organism change across development.
There are at least two possibilities for why co-modulation of learning and attention may have arisen as a part of our cognitive apparatus.
First, it may be a way to solve the problem of how to constrain perceptual capacity, and second, and more simply, it may just be the optimal strategy for navigating environments that are not perfectly stable.
@hullinger2015 provide support for the second possibility via simulations of evolved learning systems. 
They found that attention evolves as an optimal strategy even in environments that did not overwhelm agents' perceptual capacity, but only when there was some amount of change in the value of different stimuli across the agents' lifespans.
This gradual change of the diagnostic value of particular cues is very roughly analogous to what a developing organism might experience as their motives toward different kinds of social experience change. 
For this reason, reinforcement learning paradigms present an ideal (and idealized) paradigm for investigating changing motivations during development.
Even though they have been tested extensively throughout the lifespan, we know of no studies investigating how social-motive-relevant information alter stimulus salience and learning in these paradigms.

## Using reinforcement learning to investigate social motives

In reinforcement learning paradigms, incorporating social information that is relevant to adolescent-emerging social goals should enhance learning for cues that are associated with that information.
Specifically, in this study, adolescents and young adults try to learn the association between targets (images of faces) and both minimally social descriptors (Hungry, Thirsty), as well as descriptors relevant to romantic behavior (Dating, Looking [for someone to date]), and to social hierarchy (i.e., status; Popular, Unpopular).
We expect that our participants will differ in their motivation to learn the face-descriptor associations in proportion to the relevance of those descriptors to their social goals (e.g., mate-seeking, or status).
We presume that knowing whether someone is dating, or looking for someone to date would, generally, be relevant information for someone who wants to engage in romantic or sexual behavior. 
We also presume that status information is relevant to people who find themselves navigating increasingly complex social hierarchies. 
Finally, we presume that learning about another person's hunger or thirst is not especially relevant to adolescent-emerging socially motivated goals.
Past work has shown consistently that performance on reinforcement learning tasks improves with age [we return to this in the discussion, but see, e.g., @peters2017].
For this reason, any developmental-motivation effect of stimulus salience on learning should manifest over-and-above the increase in performance that would be expected from early adolescence to young adulthood.
Given the above, we hypothesized that, relative to younger participants, older participants would show faster learning of the mate-seeking and status descriptors relative to the minimally-social descriptors, and that pubertal status would also show this relation.

# Method

## Social Probabilistic Learning Task

The Social Probabilistic Learning Task (SPLT) is a standard reinforcement learning paradigm using several stimulus-word pairings that are grouped by motive relevance.
Common probabilistic reinforcement learning paradigms focus on estimating parameters that govern learning associations between stimuli using abstract images and nonsocial categories as the conditioned stimulus [e.g., a weather prediction of 'sunny' or 'rainy'; @knowlton1996].
In the SPLT, motive context is manipulated by pairing computer-generated representations of human faces with state or trait words related to mate-seeking and status motives.
The purpose of this manipulation is to examine how this motive framing alters learning, especially across adolescent development, as well as how individual differences in learning are related to the measures of attitudes and behavior outlined below.

\begin{figure}
\centering
\includegraphics[width=3.25in]{figures/trial_example} 
\caption[Example of a trial on the SPLT]{Example of a trial on the SPLT. Image shows post-response feedback phase on an incorrect trial where the participant could have earned 5 points for a correct answer, but earned 0 points.}
\label{fig:trialexample}
\end{figure}

On each trial, the participant sees one of six faces, along with two labels, and is asked to classify the face using one of the two labels.
The labels are: *Hungry* versus *Thirsty* (baseline condition that is nonsocial, or only minimally social), *Dating* versus *Looking* for someone to date (mate-seeking), and *Popular* versus *Unpopular* (status).
In order to help reduce task difficulty, "Hungry", "Dating", and "Popular" always appear on the left, while "Thirsty", "Looking", and "Unpopular" always appear on the right.
After choosing the label, the participant is given feedback that they were correct and earned either 1/1 point or 5/5 points, or that they were incorrect and earned 0/1 point or 0/5 points (Figure \ref{fig:trialexample}).
Each face is probabilistically associated with one label with P(Correct | Choice = Label) = .80.
That is, there is a probabilistically optimal choice response, which precludes a memorization strategy and results in more automatic reinforcement learning [@knowlton1996].
The participant is instructed that "the same word goes with the same picture most of the time, but not always," and to "try to guess correctly as often as you can to get the most points."

To ensure engagement with the stimulus faces, 3 unambiguously male and 3 unambiguously female faces were drawn from a set of faces evaluated by @todorov2008.
Target faces were drawn from a subset of those highest in likeability and attractiveness ratings, and were selected to have roughly equal euclidean distance from one another on the other dimensions on which they had been rated (e.g., trustworthiness).
Essentially, the faces were selected to be similarly salient, as well as similarly distinct from one another such that one or two particularly unique faces did not overwhelm the learning effect of the motives.
On each run of the task (i.e., for each participant), one male and one female face was randomly assigned to each label within condition (baseline, mate-seeking, status).
On each trial, the participant had 3.5 seconds to respond, and was shown response feedback for 1 second.
The task comprises a total of 384 trials across 8 blocks.

The receipt of the reward for choosing the optimal response (that is, the response that most often generated a reward) was probabilistic.
Across conditions and samples, the observed probability of reward receipt for an optimal choice was very close to the generative _p_ = .80 (Table \ref{tab:optpressstats}).
Reaction times for all participants can be seen in Figure \ref{fig:reactiontime}, with an overall mean of `r round(mean(dplyr::filter(splt, rt > 0, rt<3600)$rt)/1000, 2)`s (SD = `r round(sd(dplyr::filter(splt, rt > 0, rt<3600)$rt)/1000, 2)`s).
Most participants completed all trials with only occasional missed responses (Table \ref{tab:trialstats}).
For a small number of participants, far fewer trials were obtained (min = `r min(dplyr::summarize(dplyr::group_by(dplyr::filter(splt, !is.na(pressed_r)), id), n = n())$n)`, with n = `r sum(dplyr::summarize(dplyr::group_by(dplyr::filter(splt, !is.na(pressed_r)), id), n = n())$n < 350)` having fewer than 350 trials) either as a result of early termination, or because of computer error during data file saving.


\begin{table}
\centering
\begin{threeparttable}
\caption{Probability that an optimal choice results in reward} \label{tab:optpressstats}
\small
```{r optpressstats, results='asis'}
ptab(optimal_press_prop_table)
```
\begin{tablenotes}
\footnotesize
\item `r sample_abbreviation_note` PDS: Pubertal development scale. 
\end{tablenotes}
\end{threeparttable}
\end{table}

\begin{table}
\centering
\begin{threeparttable}
\caption{Number of trials completed} \label{tab:trialstats}
\small
```{r trialstats, results='asis'}
ptab(trials_table)
```
\begin{tablenotes}
\footnotesize
\item `r sample_abbreviation_note`
\end{tablenotes}
\end{threeparttable}
\end{table}



```{r reactiontime, fig.width=3.25, fig.height=2.25, include=F}
print(reaction_time_plot)
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/reactiontime-1.pdf}
\caption[Distribution of reaction times for all participants.]{\label{fig:reactiontime}Distribution of reaction times for all participants. The vertical line is set at 1s, which is close to the mean reaction time across all samples.}
\end{figure}

## Modeling approach

The focus of this analysis is on describing and estimating differences in learning that are proposed to be related to differences in motives that develop during adolescence.
The goal of such estimation is to provide reliable information about the magnitude and sign of relations between observed phenomena, as well as about the uncertainty of that information.
A Bayesian approach provides a robust framework for specifying and estimating hierarchical, nonlinear models with many parameters while constraining inferences in a way that reduces the rate of making incorrect claims with confidence [@gelman_why_2012;@GelmanPowerCalculationsAssessing2014].
These are key concerns for the current work for two reasons.
First, convergence of reinforcement learning  model can be difficult to achieve, and Bayesian estimation helps by allowing one to constrain parameter values for these models in a principled and intuitive way using parametric prior distributions.
Second, in contrast to a confirmatory experiment, this analysis seeks to explore relations between a number of theoretically related constructs; as such, the hierarchical Bayesian approach helps constrain estimates in ways that increase their efficiency [@gelman_why_2012].


## A model for reinforcement learning

In the context of this task, where the relation between the optimal response and the stimulus is constant, a simple model of the degree of learning could rely on a simple proportion of optimal responses $P_{ok}$ for each condition $k$.
The test of the hypothesis of the effect of framing would then be the difference between conditions in $P_o$. 
This simple model may sacrifices some precision for simplicity, and so we will also use a reinforcement learning model with several parameters that can account for deviations from a strict Rescorla-Wagner (RW) process.
This increases the number of possible comparisons we are able to make between conditions, which may generate useful information about how motive-domain framing affects the learning process (conditional on the model), but which also increases the complexity of patterns between conditions and parameters that must be interpreted.
It will be helpful to keep in mind that the framing can only be said to potentiate learning if, regardless of its effect on any model parameters, it also results in higher proportions of optimal responding.

The model used for these analyses is a Rescorla-Wagner model implemented by @ahn2017, which they label as their go-no-go model number 2. 
Their original model handles binary decisions (button-press or no button-press) in response to four different cues. 
However, the form of the learning algorithm is generalizable to other binary choices in response to cues. 
The go-no-go models used by @ahn2017 were derived from work by @guitart-masip2012. 
Their most flexible reinforcement learning model generates the probability of an action for each trial via five parameters: the learning rate, $\epsilon$; the effective size of reinforcement, $\rho$; a static bias parameter, $b$; an irreducible noise parameter, $\xi$; and a Pavlovian learning parameter, $\pi$.
In the SPLT, trial feedback does not vary by valence (responses result in reward, or no reward, but never punishment), so we use the model that does not include this Pavlovian component. 

## Reinforcement learning model for the SPLT

The pattern of an individual $j$'s decision to press right ($a_{\rightarrow} = 1$) versus left ($a_{\rightarrow} = 0$) is distributed Bernoulli with $a_{\rightarrow j}\sim\text{Bernoulli}(\theta_j)$. 
Each individual's vector of $\theta$ is just the probability of pressing the right arrow key, $P(a_{\rightarrow t} | s_{t})_{t}$, for each trial $t$, conditional on whatever stimulus $s$ is present on that trial. 
This probability is calculated using a logistic transformation of the action weight for pressing the right arrow key minus the action weight for pressing the left arrow key. 
This probability is then adjusted by a noise parameter, $0 \leq\xi_{jk}\leq 1$, for each participant $j$ during condition $k$.
The noise parameter modulates the degree to which responses are random. 
When $\xi = 1$, $P_{t} = .5$, and because each individual has a unique noise parameter for each condition, this allows the model to  account for participants who do not learn during any particular condition.
The full equation is:
$$
P(a_{\rightarrow t} | s_{t})_{t} = 
\text{logit}^{-1}\big(W(a_{\rightarrow t}| s_{t}) - W(a_{\leftarrow t}| s_{t})\big)\cdot(1-\xi_{jk}) + \small\frac{\xi_{jk}}{2}.
$$
The action weight is determined by a Rescorla-Wagner (RW) updating function, 
$$
W_{t}(a,s) = 
\begin{cases}
Q_{t}(a, s) + b_{jk} & \text{if}\ a=\text{press }\rightarrow\\
Q_{t}(a, s) & \text{otherwise}
\end{cases},
$$
where $b_{jk}$ encodes the degree of bias, for participant $j$ during condition $k$, toward pressing the right arrow key ($\rightarrow$).
The function $Q$ encodes instrumental learning and is governed by the individual's learning rate for that condition, $\epsilon_{jk}$, and the inverse temperature parameter, $\rho_{jk}$, that scales the effective size of the possible rewards $r_t \in \{0, 1, 5\}$:
$$
Q_{t}(a_t, s_t) = Q_{t-1}(a_t, s_t) + \epsilon_{jk}\big(\rho_{jk}r_t - Q_{t-1}(a_t, s_t)\big).
$$

### Hierarchical Parameters

Each parameter ($\epsilon, \rho, b, \xi$) varies by condition $k \in 1:K$, and by participant $j \in 1:J$ nested in sample $m \in 1:M$. 
The structure of the hierarchical part of the model is the same for each parameter, so the following description for $\epsilon$ will serve as a description for all of the parameters.
For each individual $j$, $\beta_{\epsilon j}$ is a $K$-element row of coefficients for parameter $\epsilon$ for each condition:
$$
\beta_{\epsilon j} \sim \mathcal{N}(\delta_{\epsilon mm[j]}, \Sigma_{\epsilon})
$$
where $\delta_{\epsilon mm[j]}$ is a column of $K$ means for individual $j$'s sample $M$, as indexed in the vector $mm$, and $\Sigma_{\epsilon}$ is a $K\times K$ matrix of the covariance of individual coefficients between conditions.

Finally, across all $M$ samples, the means for each condition k are distributed such that: 
$$
\delta_{\epsilon k} \sim \mathcal{N}(\mu_{\epsilon k}, \sigma_\epsilon)
$$
where $\mu_{\epsilon k}$ is the population mean for parameter $\epsilon$ in condition $k$, and $\sigma$ is a slightly regularizing scale parameter for these means across all conditions and samples. The priors for these final parameters are:
$$
\begin{split}
\mu_\epsilon &\sim \mathcal{N}(0, 5)\\
\sigma_\epsilon &\sim \text{exponential(1)}.
\end{split}
$$

All $\beta$ are transformed to be on the appropriate scale before being used to compute $\theta_t$.
For $\epsilon$ and $\xi$, values are transformed to be on $[0,1]$ using the fast approximation to the unit normal cumulative distribution function, $\phi_{\text{approx}}(x)$.
The parameter $\rho$ is transformed to be on $[0,\infty)$ using the exponential function, $e^x$.
The bias parameter $b$ does not need any transformation.

## Simulating data

Before modeling the task data, we will confirm that this model can recover known parameters from simulated data.
Using RStan [version `r packageVersion('rstan')`; @standevelopmentteam2018], we simulate 100 data sets based on the structure of the sample data, using the same number of participants per sample, as well as precisely the same task structure. 
For this analysis, it is important to be able to recover all $\mu_{\theta k}$ for $\theta \in \{\epsilon,\rho,b,\xi\}$ and $k \in \{1,2,3\}$, where 1 = Hungry/Thirsty, 2 = Popular/Unpopular, and 3 = Dating/Looking. 
Based on interactive simulation [online at https://jflournoy.shinyapps.io/rw_model/; @flournoy2018], reasonable parameter values for the control condition might be $\mu_{\epsilon^\prime} = -1.65$ and $\mu_{\rho^\prime} = -0.3$ (note that these are the _raw_ parameter values, on the scale the priors are defined, and which are transformed before being used in the learning model).

One early indication that a model may not be well suited to describing the data is that when generating from the prior distribution, simulated data-sets either do not adequately cover the range of reasonable values, or cover ranges that are implausible [@gabry2017].
The simulated data do generally cover the range of the actual data when we look just at the proportion of optimal presses over time (Figure \ref{fig:simdatcoverage}), and importantly do not show implausible behavior (e.g., most estimates around extreme values like 0, 1, or .5).

```{r simdatcoverage, fig.width=5.875, fig.height=4, include=F}
print(nosmooth_multi_plot)
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/simdatcoverage-1.pdf}
\caption[Model-simulated task data]{Model-simulated task data. Each point is the mean of optimal presses on that trial, for the indicated condition, from 1 of 100 simulated data sets using just the model prior distributions. The red line is at .5, corresponding to random responding. It is apparent that the model priors allow coverage of the entire range of realistic responses.}
\label{fig:simdatcoverage}
\end{figure}

The priors also generate reasonable ranges for the model parameters across these 100 simulations. 
Notably, the mass of the prior distributions is distributed across the full range of reasonable values at each level and will tend to shrink posterior distributions toward zero if the data do not overwhelm the prior distributions.
Ultimately, draws from the prior distributions transformed into predicted behavior based on the learning model described above generate a prior distribution over an agent's hypothetical final probability (at task-end) of choosing the word on the right-hand side of the screen.
In a model that is well calibrated to this task, but that does not bias estimates, we should observe that these prior probabilities cover the full range, [0,1], for each of the six cues.
These distributions cover the full range, with most mass around the null value of the final probability = .5 for choosing the left or right option (Figure \ref{fig:sampleprfinaldens}).
If the data does not overwhelm the prior distribution, we can be assured that the prior is not biasing the estimate away from random responding.

```{r sampleprfinaldens, fig.width=3.25, fig.height=2, include=F}
sample_pR_final_dens
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/sampleprfinaldens-1.pdf}
\caption[Prior density of task-end press-right probability]{Prior density of task-end press-right probability. Across 100 simulated data sets, prior probabilities on learning-model parameters favor low rates of learning to discriminate optimal choices. There is, however, mass across the entire range of realistic values.}
\label{fig:sampleprfinaldens}
\end{figure}

## Recovery of population parameters

After generating these simulated data sets and known parameter values, the model was then fit to these simulated data to evaluate its ability to recover the parameters. 
The mode was fit using 6 chains with 1200 warm-up iterations and 334 sampling iterations per chain (for a total of 2004 samples). 
An example from one simulation of estimated posterior densities for the final probability of a participant choosing the right-hand label shows that nearly all posterior 95% credible intervals capture the underlying generating parameter (Figure \ref{fig:pRfinalplot}).
This is also the behavior seen for individual parameters unless the simulated data come from a prior draw where the variation between individuals is extremely low, or a particular parameter (like the noise parameter, $\xi$) overwhelms the other parameters in leading to the simulated behavior.

```{r pRfinalplot, fig.width=5.875, fig.height=4, include=F}
ggplot2::theme_set(ggplot2::theme_minimal())
do.call(gridExtra::grid.arrange, pR_final_plots)
```

&nbsp;

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/pRfinalplot-1.pdf}
\caption[Correspondence of simulation generated and estimated behavior]{Correspondence of simulation generated and estimated behavior. The X-axis indexes the simulation-generated final-trial right-hand button-press probability ($P_\text{r-final}$), and the Y-axis indexes the estimated posterior median $P_\text{r-final}$. Whiskers indicate the posterior 2.5\% and 97.5\% quantiles.}
\label{fig:pRfinalplot}
\end{figure}

While the above example provides some reassurance that the model performs adequately on simulated data, it is important to evaluate that it can perform well across a number of data sets.
To examine the performance of all of the simulations, after the posteriors for each simulation estimate were sampled, the empirical cumulative density function was composed for the distribution of each parameter. 
The cumulative density _at the generating value_ (from the simulation) was then found. 
This procedure is the same as finding the _p_-value for a test statistic using the probability density function for the relevant distribution (e.g., the student _t_ or normal).
If the posterior is reasonable, then the generating parameter should be a random draw from that posterior, and if the posterior consistently tends toward excluding the generating value, we would expect the generating value to fall more often on one side or the other of the posterior. 
As such, the distribution of the _p_-value of the generating parameters (in relation to the posteriors) should be uniform (for the same reason that _p_-values are expected to be uniform if the null hypothesis is true).
This is indeed what we find both from a visual inspection of the deviation of the cumulative density of the posterior probabilities of generating values (Figure \ref{fig:densityplots}) and from Kolmogorov-Smirnov tests, which do not reject the null hypothesis that there are no differences between the observed _p_-values and the uniform distribution on [0,1]. 
Note, however, that power to reject this null hypothesis (at $\alpha = .05$) may be somewhat limited for the estimated population parameters from just a small number (N = 100) of simulations.

```{r densityplots, fig.width=5.875, fig.height=4, include=F}
ggplot2::theme_set(ggplot2::theme_minimal())
gridExtra::grid.arrange(mu_unif_dens_plot, beta_unif_dens_plot, ncol = 2, widths = c(3,2))
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/densityplots-1.pdf}
\caption[Posterior probabilities of generating values versus uniform]{Posterior probabilities of generating values versus uniform. The empirical density of the posteriors probabilities of the data generating values (that is, the probability of the generating value assuming the posterior density is what it is drawn from) do not seem to deviate greatly or systematically from the cumulative uniform density function. Kolmogorov-Smirnov tests did not reject the hypothesis of no difference between these posterior probabilities and the uniform distribution on [0,1].}
\label{fig:densityplots}
\end{figure}

## Target model and estimation of sample parameters

All models were fit in RStan [version `r packageVersion('rstan')`; @standevelopmentteam2018] using R [version `r paste(version$major,version$minor, sep = '.')`; @rcoreteam2018].
Samples were drawn over 1534 iterations from six chains per model, with the first 1200 iterations for each chain discarded as a warm-up period (total iterations per model = 2004).
To compare models and choose the one with the best expected out-of-sample prediction we used the R package, loo [@vehtari2018], to compute an estimate of the leave-one-individual-out cross validation information criterion [@vehtari2017a].

From the winning model, we then extracted model parameters, as well as the final probability of choosing the optimal descriptor for a particular cue.
Means of the posterior densities for all parameters are used in subsequent analyses.
In addition, we used the average number of optimal choices in the last half of the run as a more easily calculable measure of optimal performance.
Associations between all model parameters, measures of performance, age, and pubertal development are computed using Spearman's rank order correlation and standardized coefficients from linear mixed effects models.
Linear mixed effects (LME) models were computed using the R package lme4 [version `r packageVersion('lme4')`; @bates2015].
These LME models were computed in order to aid descriptions of plotted data and best-fit generalized additive model (GAM) lines, and were used in place of correlations to account for non-independence of data when, for example, a parameter for all three conditions was regressed on age.
All such models have the form $y_{ij} = \gamma_{00} + \gamma_{10}\text{x}_j + u_{0j} + e_{ij}$, where $y$ is a target outcome like the learning rate $\epsilon$, and $\text{x}$ is a predictor like age or score on the pubertal development scale.
The standardized $\gamma_{10}$ coefficient (labeled as $\beta$ in the tables below) is then used to help describe the magnitude of relations seen in the plots.

# Results

```{r}
rm(list = ls())
load('rda/fit-model-to-participant-data.rda')
```

```{r}
grid_arrange_shared_legend <- function(..., ncol = 1, widths) {
  plots <- list(...)
  g <- ggplot2::ggplotGrob(plots[[1]] + 
                             ggplot2::theme(legend.position="bottom")+
                             ggplot2::guides(linetype = ggplot2::guide_legend(override.aes=list(fill=NA)),
                                             shape = ggplot2::guide_legend(override.aes=list(alpha=.5))))$grobs
  legend <- g[[which(sapply(g, function(x) x$name) == "guide-box")]]
  lheight <- sum(legend$height)
  gridExtra::grid.arrange(
    do.call(gridExtra::arrangeGrob, c(lapply(plots, function(x)
      x + ggplot2::theme(legend.position="none")), list(ncol = ncol, widths = widths))),
    legend,
    nrow = 2,
    heights = grid::unit.c(ggplot2::unit(1, "npc") - lheight, lheight))
}
```

## Descriptive data

Examination of non-parametric trends in trial-by-trial average number of optimal presses indicates that learning occurs in each sample, and condition (Figure \ref{fig:trialaverages}A). 
There is also an indication that learning occurs more quickly and optimal presses are generally more frequent in the two social-motive conditions relative to the minimally social condition (Figure \ref{fig:trialaverages}B).

```{r trialaverages, fig.width=5.875, fig.height=4, include=F}
ggplot2::theme_set(ggplot2::theme_minimal())
avg_per_sample_plot2 <- avg_per_sample_plot + 
  ggplot2::facet_wrap(~sample, nrow = 2, 
                      labeller = ggplot2::label_wrap_gen(width = 20))

grid_arrange_shared_legend(avg_per_sample_plot2, avg_across_samples, ncol = 2, widths = c(1.3,1))
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/trialaverages-1.pdf}
\caption[Average optimal behavior over trials]{Average optimal behavior over trials. Each point is the average across participants for that trial for the indicated condition. Best fit lines and confidence bands are estimated using generalized additive models.}
\label{fig:trialaverages}
\end{figure}

## Model estimated parameters

### Model comparisons

Six models were fit to the data and compared using an estimate of leave-one-participant-out cross-validation prediction accuracy. 
In the first set of three models, parameters were estimated for individuals, nested within sample (resulting in parameter estimates for the population, each sample, and each individual). 
The second set of three models dropped the sample grouping.
The maximal model for each group included parameters (for each condition) for the learning rate ($\epsilon$), reward modifier (also referred to as inverse temperature; $\rho$), irreducible noise ($\xi$), and right-arrow bias ($b$).
A second model in each group dropped the parameter, $b$, while the third model dropped both $b$ and $\rho$.
While the maximal model provides the highest expected predictive accuracy, there is little difference between models that account for grouping of participants within sample versus those that don't -- simply allowing each individual's parameters to differ is sufficient for capturing any overall difference between samples. 
We can also verify that parameter estimates change very little between the two- and three-level specifications, showing near perfect correlation (Figure \ref{fig:twothreecorplot}).
Correlations of individual-level estimates of the same parameters between all two-level models were also very high ($r_{\epsilon1,2,3} > .89, r_{\xi1,2,3} > .87, r_{\rho1,2} = .79$).
In the maximal, two-level model, correlations between parameters were generally quite small, although there is a somewhat more systematic relation when looking at the noise parameter, $\xi$ (Figure \ref{fig:corparplot}).

\begin{table}
\centering
\begin{threeparttable}
\caption{Model comparison} \label{tab:loocomp}
\small
```{r loocomp, results='asis'}
loo_rownames <- c(
  'splt-looser-rl_repar_exp-1528144.RDS' = '3-level, maximal',
  'splt-looser-rl_2_level-1528266.RDS' = '2-level, maximal',
  'splt-looser-rl_repar_exp_no_b-1528233.RDS' = '3-level, without parameter b',
  'splt-looser-rl_2_level_no_b-1527784.RDS' = '2-level, without parameter b',
  'splt-looser-rl_repar_exp_no_b_no_rho-1527735.RDS' = '3-level, without parameters b, $\\rho$',
  'splt-looser-rl_2_level_no_b_no_rho-1527729.RDS' = '2-level, without parameters b, $\\rho$')[dimnames(loo_comp)[[1]]]
loo_comp_rn <- cbind(Model = loo_rownames, apply(loo_comp, 2, function(col) sprintf('%0.2f', col)))
knitr::kable(loo_comp_rn[,c('Model', 'elpd_diff', 'looic')], 
             col.names = c('Model', '$\\Delta$ ELPD', 'LOOIC'),
             row.names = F, format = 'latex', escape = F, align = c('l', 'r', 'r'),
             booktabs = TRUE)
```
\begin{tablenotes}
\footnotesize
\item $\Delta$ ELPD is the change in expected log predictive density from the best fitting model. LOOIC is the leave-one-out information criterion -- like other information criteria, smaller values are better.
\end{tablenotes}
\end{threeparttable}
\end{table}

```{r twothreecorplot, fig.width=5.875, fig.height=4, include=F}
gridExtra::grid.arrange(grobs = two_three_level_comparison_plots,
                        ncol = 3)
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/twothreecorplot-1.pdf}
\caption[Correlation between three- and two-level model parameters]{Correlation between three- and two-level model parameters. Each individual-level parameter for the three-level maximal model is plotted against that for the two-level maximal model (for all conditions). The values of $P(\text{right})_{t = \text{T}}$ are the probabilities of pressing the right arrow for the final trial, T, for each participant for each condition.}
\label{fig:twothreecorplot}
\end{figure}

```{r corparplot, fig.width=5.875, fig.height=4, include=F}
print(par_mean_cor_plot_max2l)
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/corparplot-1.pdf}
\caption[Correlation between parameters in the 2-level, maximal model]{Correlation between parameters in 2-level maximal model. Points are poster means of individual parameter estimates. All parameters are shown on their untransformed (i.e., unconstrained) scales. Black lines are LOESS curves. The diagonal shows the count, while the upper triangle shows Spearman correlation coefficients. $\xi$: noise; $\rho$: reward modifier; $\epsilon$: learning rate; $b$: right-arrow bias.}
\label{fig:corparplot}
\end{figure}


### Validation of parameters with respect to behavior

In order to build further confidence in the plausibility of the estimated individual-level parameters, it may be helpful to examine how they relate to the proportion of optimal choices during the last half of the task run, when learning appears to be reaching its completion, and performance, on average, is plateauing.
First, we should see that performance should be worse for people with high estimated $\xi$ (noise) parameters relative to participants with similar values of other parameters.
Second, we should also see that, all else equal, both higher estimates for $\rho$ (reward modifier), and $\epsilon$ (learning rate), should be associated with better performance up to an optimal point, from which performance decreases.
This curvilinear relation is due to the fact that because the task is probabilistic, the participant sometimes receives feedback in favor of the non-optimal choice.
When $\rho$, $\epsilon$, or both are very high, the learner may behave as if early but misleading feedback takes precedence over later feedback, or they may behave as if each new piece of feedback is the most important information for guiding their next decision.
This is precisely what we see in these data.
For each panel in Figure \ref{fig:parametersvbehavior}, $\rho$ increases along with the overall proportion of optimal responses; as $\xi$ increases (mapped from red to blue, and also tracked by a split indicated by solid and dotted lines), optimal responding is diminished no matter what the estimate of the other parameters; and though we do not see the sweet spot for $\rho$, we do see that as $\rho$ increases, the sweet spot for $\epsilon$ becomes more pronounced, with optimal responding increasing until, approximately, $\epsilon > .1$.
  
```{r parametersvbehavior, fig.width=5.875, fig.height=4, include=F}
allparameter_plot
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/parametersvbehavior-1.pdf}
\caption[Run-end optimal press behavior and RW learning parameters]{Run-end optimal press behavior and RW learning parameters. Each point is data from one condition for a single participant. As the learning rate parameter, $\epsilon$, increases (X-axis), probability of making an optimal choice increases to a maximum and then decreases. Panels bin increasing values of the reward modifier, $\rho$, which also shows increasing optimal choice with larger values. However, as expected, higher values of the noise parameter, $\xi$ (dotted line), suppress the associations between optimal choice behavior and the other two parameters.}
\label{fig:parametersvbehavior}
\end{figure}
  
Very similar patterns are apparent between the parameters and the confidence participants had in their choices.
At the end of each of 8 blocks (48 choices each), participants were asked, generally, how well they thought they knew which word went with which face.
Scatter-plots and generalized additive model best-fit lines (Figure \ref{fig:confidencevparameters}) show striking relations between  global confidence ratings and both higher $\rho$ ($r = .37, 99.5\%\text{ CI} = [.22,.50]$), and lower $\xi$ ($r = -.34, 99.5\%\text{ CI} = [-.48,-.19]$) that mirror the relations to optimal choices seen above ($\epsilon$ also shows a smaller negative relation to confidence; $r = -.12, 99.5\%\text{ CI} = [-.27,.05]$).
This implies, at least, that the participants are aware of the general reward-optimality of their behavior, so that the model parameters, which show systematic relations to that behavior, also correlate with confidence ratings.

```{r confidencevparameters, fig.width=5.875, fig.height=4.1, include=F}
parameter_lookup <- c(
  ep_prm = 'epsilon',
  rho_prm = 'rho',
  xi_prm = 'xi',
  b = 'b'
)

confidence_parameter_plot +
  ggplot2::facet_grid(condition ~ parameter, scales = 'free_x', 
                      labeller = ggplot2::labeller(
                        parameter = ggplot2::as_labeller(parameter_lookup,
                                                         default = ggplot2::label_parsed)))
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/confidencevparameters-1.pdf}
\caption[Confidence in learning and RW learning parameters]{Confidence in learning and RW learning parameters. Each point is the confidence rating for a single participant at the end of all trials (and because each participant has only one rating, a participant's value on the Y-axis is the same across all panels). A clear association between the reward modifier, $\rho$, and confidence, and the noise parameter, $\xi$, and confidence can be seen. The right-arrow bias, $b$, and learning rate, $\epsilon$, do not show clear associations with confidence.}
\label{fig:confidencevparameters}
\end{figure}

## Population-level parameters

```{r}
lowfi_ht_dl_t <- PairedData::yuen.t.test(
  lowfi_df$bin_5_to_end[lowfi_df$condition == 'Dating/Looking'], 
  lowfi_df$bin_5_to_end[lowfi_df$condition == 'Hungry/Thirsty'], 
  paired = T)
apa_lowfi_ht_dl_t <- paste0('*t*(', lowfi_ht_dl_t$parameter, ') = ', round(lowfi_ht_dl_t$statistic,2), 
               ', *p* = ', round(lowfi_ht_dl_t$p.value, 3), 
               ', $\\bar{D}$ = ', round(lowfi_ht_dl_t$estimate,3), 
               ', $\\text{CI}_{.95} = [', paste(round(lowfi_ht_dl_t$conf.int,3), collapse = ','), ']$')

lowfi_ht_pu_t <- PairedData::yuen.t.test(
  lowfi_df$bin_5_to_end[lowfi_df$condition == 'Popular/Unpopular'],
  lowfi_df$bin_5_to_end[lowfi_df$condition == 'Hungry/Thirsty'], 
  paired = T)
apa_lowfi_ht_pu_t <- paste0('*t*(', lowfi_ht_pu_t$parameter, ') = ', round(lowfi_ht_pu_t$statistic,2), 
               ', *p* = ', round(lowfi_ht_pu_t$p.value, 5), 
               ', $\\bar{D}$ = ', round(lowfi_ht_pu_t$estimate,3), 
               ', $\\text{CI}_{.95} = [', paste(round(lowfi_ht_pu_t$conf.int,3), collapse = ','), ']$')
```

Overall, learning was potentiated in the Dating/Looking, and Popular/Unpopular conditions.
Comparing the proportion of optimal choices in the last half of the run, paired sample Yuen *t*-tests [computed using the PairedData package; @champely2017], which are robust to non-normality [@yuen1974], reject the null of no difference between the two conditions of interest and the control condition (Dating/Looking: `r apa_lowfi_ht_dl_t`; Popular/Unpopular: `r apa_lowfi_ht_pu_t`).
The differences in observed behavior are also reflected in some parameter estimates.
The 99.5% credible intervals for the difference in learning rate, $\epsilon$, between the two social conditions and the minimally social condition are both well above 0, while the difference between the two social conditions has much of its mass close to 0 (Figure \ref{fig:epsdiff}).
This indicates that, on average, individuals' learning rates in the social conditions are larger relative to the minimally social condition, but are not very different between them (although there is some not insubstantial probability that the Popular/Unpopular learning rate is of the greatest magnitude).
Differences in the population mean of the reward modifier, $\rho$, have large portions of the posterior probability mass both above and below 0 for all contrasts (Figure \ref{fig:rhodiff}).
Although there is a bit more variability in the contrasts between the social conditions and the reference condition, the social manipulation does not have a very strong or systematic effect on this model parameter.
The estimated difference in the irreducible noise parameters, $\xi$, is also not convincingly positive or negative for any of the contrasts, although the majority of the probability mass for the social versus reference contrasts does lie below 0 (Figure \ref{fig:xidiff}).
This suggests that there may be less random responding in the social conditions relative to the reference condition.
Finally, differences in right-bias, $b$, are also not convincingly either positive or negative, although there is a suggestion of greater tendency toward choosing the left social option (Dating, median $b = -0.11, \text{CI}_{.995} = [-0.20,-0.02]$; Popular, median $b = -0.10, \text{CI}_{.995} = [-0.19,-0.01]$) than the left reference option (Thirsty, median $b = -0.05, \text{CI}_{.995} = [-0.12,0.034]$; Figure \ref{fig:bdiff}).
The descriptors, "Hungry", "Dating", and "Popular" always appeared on the left, so the credibly negative medians for each of the social conditions, as well as the suggestion of difference between the social and reference conditions, may indicate that participants favored choosing the socially desirable descriptors (as opposed to "Looking" and "Unpopular") for some reason.

```{r epsdiff, fig.width=3.5, fig.height=2, include=F}
epsilon_difference_plot
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/epsdiff-1.pdf}
\caption[Condition contrasts for learning rate, $\epsilon$]{Condition contrasts for learning rate, $\epsilon$. Subscript number denotes condition. Condition 1 is Hungry/Thirsty, Condition 2 is Dating/Looking, Condition 3 is Popular/Unpopular. Shaded region is 95\% credible region, and tails extend to 99.5\% credible region.}
\label{fig:epsdiff}
\end{figure}

```{r rhodiff, fig.width=3.5, fig.height=2, include=F}
rho_difference_plot
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/rhodiff-1.pdf}
\caption[Condition contrasts for reward modifier, $\rho$]{Condition contrasts for reward modifier, $\rho$. Subscript number denotes condition. Condition 1 is Hungry/Thirsty, Condition 2 is Dating/Looking, Condition 3 is Popular/Unpopular. Shaded region is 95\% credible region, and tails extend to 99.5\% credible region.}
\label{fig:rhodiff}
\end{figure}

```{r xidiff, fig.width=3.5, fig.height=2, include=F}
xi_difference_plot
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/xidiff-1.pdf}
\caption[Condition contrasts for noise, $\xi$]{Condition contrasts for noise, $\xi$. Subscript number denotes condition. Condition 1 is Hungry/Thirsty, Condition 2 is Dating/Looking, Condition 3 is Popular/Unpopular. Shaded region is 95\% credible region, and tails extend to 99.5\% credible region.}
\label{fig:xidiff}
\end{figure}

```{r bdiff, fig.width=3.5, fig.height=2, include=F}
b_difference_plot
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/bdiff-1.pdf}
\caption[Condition contrasts for right-arrow bias, $b$]{Condition contrasts for right-arrow bias, $b$. Subscript number denotes condition. Condition 1 is Hungry/Thirsty, Condition 2 is Dating/Looking, Condition 3 is Popular/Unpopular. Shaded region is 95\% credible region, and tails extend to 99.5\% credible region. Positive values indicate bias toward right-button responding (i.e., "Thirsty", "Looking", "Unpopular"), negative values toward left-button responding (i.e., "Hungry", "Dating", "Popular").}
\label{fig:bdiff}
\end{figure}

Given the dynamic nature of the task and non-intuitive contributions of model parameters to probabilities of choosing one option over another, the consequences of these differences between conditions may captured more clearly by an example of the kinds of behavior these parameters could give rise to.
A helpful approach might be to generate behavior over many identical runs using a hypothetical actor that takes on these population-level mean parameters (specifically, their posterior means).
Doing so, we can look at the many possible paths through the paradigm that might be traversed by this actor who represents an "average" participant (though there may be no such real participant in existence, so this is merely illustrative).
Looking at the plot of 313 simulated runs in Figure \ref{fig:modpred} reveals a very slight effect of the bias toward choosing the left option (i.e., "Hungry", "Dating", "Popular"; visible most easily at trial 0), as well as a more profound effect of parameter differences on both the magnitude of the actor's probability of choosing optimally, as well as the variance in that probability. 
The simulated behavior suggests that in the social condition this actor may progress much more rapidly toward certainty, with much stronger certainty, eventually, but also that there is the potential to be wildly wrong about the long-run optimal choice during some of the run.

```{r modelpredictedbehavior, fig.width=5.875, fig.height=4, include=F}
model_mean_predicted_behavior_plot
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/modelpredictedbehavior-1.pdf}
\caption[Model predicted behavior]{Model predicted behavior. Each gray line follows a simulated agent's probability of choosing the optimal descriptor over one of 313 identical stimulus presentations. The stimulus presentation is randomly generated for each of the two cues and repeated for each condition, but the agent's learning parameters, $\epsilon$, $\rho$, $\xi$, and $b$ are set at the estimated population means for each condition (left-arrow press is optimal for cue 0, right-arrow press is optimal for cue 1). Two simulated runs were chosen randomly to highlight unique trajectories through the task.}
\label{fig:modpred}
\end{figure}


## Age, puberty, and learning

```{r}
load('rda/age-learning-association.rda')
```

Relations between measurements of development and both observed behavior as well as model parameters are explored below.
The presentation of results focuses first on scatter-plots of the data and GAM trend lines, which are then interpreted with the aid of standardized coefficients form LME models.
Note that age for the adolescent samples is calculated using the session date and the participant's birthday, while the young adult sample only provided their age, in years, as an integer.

The reliability of the proportion of optimal decisions and the individual-level model-estimated parameters is important to consider when interpreting the correlations with other individual differences measures.
Proportions of variance accounted for by participant-level random effects was calculated from a generalized linear mixed effects model implemented in the lme4 package.
The model included population and participant-level effect terms for each condition (with Hungry/Thirsty as the reference condition), the trial number, and an interaction between trail number and condition to account, crudely, for learning.
The proportion of variance denominator was calculated by summing the variance of all participant-level effects with the residual variance for binomial logistic regression equal to $(15/16)^2\pi^2/3$.
The proportion of total variance accounted for by individual differences in optimal presses (averaged across the run) in the Hungry/Thirsty condition was .25. Individual differences in the difference in optimal responding to the two social conditions accounted for and additional .13 (Dating/Looking) and .14 (Popular/Unpopular).
The proportion of variance accounted for by the linear effect of trial number in all three conditions was very small (.02 for each of the three conditions).

Reliability of individual differences in the model for reinforcement learning was calculated for each parameter by dividing the variance in the means of the participant-level posterior distributions by the total variance across all the samples in the posterior distributions.
In other words, we take the variance in the means of the individual parameters and divide it by the total uncertainty around those means (which also includes the variance of the means themselves).
The contrasted parameters of primary interest.
Individual-level mean posterior differences between the learning rate $\epsilon_\text{Dating/Looking}$ and $\epsilon_\text{Hungry/Thirsty}$ account for .31 of the total variance in the posterior distributions for this contrast.
For $\epsilon_\text{Popular/Unpopular} - \epsilon_\text{Hungry/Thirsty}$, the proportion is .33.
For the reward modifier, $\rho$, the proportions for the contrasts are Dating/Looking (DL) = .23 and Popular/Unpopular (PU) = .25; for the noise parameter, $\xi$, DL = .22, PU = .26; and for right-arrow bias, $b$, DL = .43, PU = .42.


### Mean optimal presses

First, we examine the relation between the proportion of optimal choices during the last half of the run for each condition relative to age and mean scores on the pubertal development scale (PDS). 
Older participants appear to make more optimal choices up until about age 18 years, at which point this positive relation seems to flatten out (Figure \ref{fig:poptageplot}).
Scores on the PDS show a very similar pattern (Figure \ref{fig:poptpdsplot}).
To quantify the magnitude of these trends, we calculated standardized regression coefficients from the fixed effects of a LME model separately for the adolescent and college samples.
With respect to age, sample is almost totally confounded, and so the magnitude of relation in the adolescent sample stands in for the relation during early to late adolescence, while the magnitude of relation in the college sample stands in for the relation during late adolescence and early adulthood.
With respect to the PDS, although there is considerably less variability in the college sample as compared to the adolescent sample, there is actually _some_ variance, and so standardized coefficients are presented for the PDS for each subset as well.
The magnitude of these trends is positive, though fairly small, with both age and PDS showing the largest standardized regression coefficients associations in the adolescent sample (Table \ref{tab:lowfidev}).
In the college sample, the relation between optimal choice proportion and age is estimated to be essentially 0, while PDS shows a positive trend (with a smaller magnitude than in the adolescent sample).


```{r poptageplot, fig.width=5.875, fig.height=3.25, include=F}
p_opt_age_plot + ggplot2::labs(x = 'Age (years)', linetype = 'Condition')
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/poptageplot-1.pdf}
\caption[Probability of optimal response versus age]{Probability of optimal response versus age. Optimal choice probability is calculated as the proportion of optimal choices in the last half of the run. All best-fit lines are from generalized additive models. Grey line is fit to all data.}
\label{fig:poptageplot}
\end{figure}

```{r poptpdsplot, fig.width=5.875, fig.height=3.25, include=F}
p_opt_pds_plot
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/poptpdsplot-1.pdf}
\caption[Probability of optimal response versus puberty]{Probability of optimal response versus puberty. Optimal choice probability is calculated as the proportion of optimal choices in the last half of the run. All best-fit lines are from generalized additive models. Grey line is fit to all data. PDS = Pubertal Development Scale.}
\label{fig:poptpdsplot}
\end{figure}

Examining the relation between optimal choice improvements in social conditions and age reveals fairly flat associations (Figure \ref{fig:poptdiffpdsplot}).
Consistent with the data plot, there is a very small but positive coefficient between age and the optimal choices contrast in the Adolescent group, and an even smaller coefficient in the college group (Table \ref{tab:lowfidev}; note that the trend in the plot appears to be slightly negative -- the trends here are so close to zero that slightly negative is not so different from slightly positive).
The plots of optimal choice improvement in social conditions versus the PDS also show relatively flat trends, with much more uncertainty with regard to the relation at low ends of the PDS, where the data are extremely sparse (Figure \ref{fig:poptdiffpdsplot}).
This is echoed in the magnitude of the standardized coefficients which are both very small (Table \ref{tab:lowfidev}).

```{r poptdiffageplot, fig.width=5.875, fig.height=3.25, include=F}
p_opt_diff_age_plot + ggplot2::labs(x = 'Age (years)')
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/poptdiffageplot-1.pdf}
\caption[Condition differences in probability of optimal response versus age]{Condition differences in probability of optimal response versus age. Optimal choice probability is calculated as the proportion of optimal choices in the last half of the run. Difference scores are calculated versus the baseline, Hungry/Thirsty, condition. All best-fit lines are from generalized additive models. Grey line is fit to all data.}
\label{fig:poptdiffageplot}
\end{figure}

```{r poptdiffpdsplot, fig.width=5.875, fig.height=4, include=F}
p_opt_diff_pds_plot
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/poptdiffpdsplot-1.pdf}
\caption[Condition differences in probability of optimal response versus puberty]{Condition differences in probability of optimal response versus puberty. Optimal choice probability is calculated as the proportion of optimal choices in the last half of the run. Difference scores are calculated versus the baseline, Hungry/Thirsty, condition. All best-fit lines are from generalized additive models. Grey line is fit to all data. PDS = Pubertal Development Scale.}\label{fig:poptdiffpdsplot}
\end{figure}

\begin{table}
\centering
\begin{threeparttable}
\caption{Associations of optimal performance with developmental differences} \label{tab:lowfidev}
\small
```{r lowfidev, results='asis'}
knitr::kable(
    dplyr::select(lowfi_regression_table, -Parameter),
    escape = F,
    format = 'latex', 
    booktabs = T,
    col.names = c('Variables', 'Age-group', '$\\beta$', '$\\text{SE}_{\\beta}$', '$t$'),
    digits = 2)
```
\begin{tablenotes}
\footnotesize
\item Optimal choice outcome was calculated for each condition. The optimal choice contrasts outcome includes just the contrasts between the proportions for the social conditions versus the proportions during the Hungry/Thirsty condition.
\end{tablenotes}
\end{threeparttable}
\end{table}


### Age and parameters

While the relation of developmental differences to overall performance can provide a broad view of possible differences that may be related to maturation, it is possible that the latent causes (as operationalized by model parameters in these analyses) of behavior change in different ways.
Using a similar approach as above, each parameter is plotted as a function of age or PDS, overlayed with GAM best fit lines for the average of all conditions, and separately for each condition. 
Inferences from these descriptive plots are then aided by the use of standardized regression coefficients of the average linear relation between the developmental variable and parameter posterior mean (or mean contrast) from a LME model that accounts for the non-independence of observations.
Again, this coefficient is estimated separately for each sample.

Both the reward magnitude, $\rho$, and irreducible noise, $\xi$, parameters show age relations that are consistent with what we see above regarding the relations of both parameters and age to performance. 
Specifically, $\rho$ is bigger and $\xi$ is smaller for older participants, at least up until about age 18 years (Figure \ref{fig:ageparplots}).
This corresponds to small standardized coefficients (positive and negative for $\rho$ and $\xi$, respectively) in the adolescent age group, and much smaller coefficients in the college age group (Table \ref{tab:agebetas}).
The relation between age and both $b$ and $\epsilon$ is much more flat, although the learning rate $\epsilon$ seems to show slightly more variability over the age span (Figure \ref{fig:ageparplots}).
The almost negligible standardized coefficients for $\epsilon$ indicate a very small negative relation in the adolescent group, and a very small positive relation in the college group, while $b$ shows a very small positive relation with age in the adolescent group (Table \ref{tab:agebetas}).


```{r ageparplots, fig.width=5.875, fig.height=4, include=F}
age_par_plot + ggplot2::labs(x = 'Age (years)')
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/ageparplots-1.pdf}
\caption[Reinforcement learning model parameters versus age]{Reinforcement learning model parameters versus age. All best-fit lines are from generalized additive models. Grey line is fit to all data. Parameters are plotted on the unconstrained scales with possible values in $(-\infty, \infty)$. $\epsilon$: learning rate; $\rho$: reward modifier; $\xi$: noise; $b$: right-arrow bias.}
\label{fig:ageparplots}
\end{figure}

The difference between the parameters in the social conditions versus the minimally social reference condition across this developmental span is one of the primary observations that bears on the question about whether motive effects on learning reflect what would be expected based on the theories discussed in the introduction.
Observations consistent with those theories would be age-increasing differences in the contrast between parameters for learning during the social versus reference conditions.
These slopes of the contrasts with respect to age are very flat for all parameters, with a very slight increase for $\epsilon$, and decrease for $\rho$ (Figure \ref{fig:ageparconplots}).
The standardized coefficients, nearly all very small, mirror the best fit lines, although the estimate for $\epsilon$ in the adolescent sample is small and negative (Table \ref{tab:agebetascon}).


```{r ageparconplots, fig.width=5.875, fig.height=4, include=F}
age_par_con_plot + ggplot2::labs(x = 'Age (years)')
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/ageparconplots-1.pdf}
\caption[Reinforcement learning model parameter condition contrasts versus age]{Reinforcement learning model parameter condition contrasts versus age. All best-fit lines are from generalized additive models. Grey line is fit to all data. Differences are calculated using parameters transformed to be on the model scale. $\epsilon$: learning rate; $\rho$: reward modifier; $\xi$: noise; $b$: right-arrow bias.}
\label{fig:ageparconplots}
\end{figure}

\begin{table}
\centering
\begin{threeparttable}
\caption{Age and parameter estimates} \label{tab:agebetas}
\small
```{r agebetas, results='asis'}
colnames <- c('Parameter', 'Age-group', '$\\beta$', '$\\text{SE}_{\\beta}$', '$t$')
knitr::kable(age_param_betas_table, digits = 2, escape = F, 
             col.names = colnames, format = 'latex', 
             booktabs = T)
```
\begin{tablenotes}
\footnotesize
\item Models were estimated using posterior mean parameters on unconstrained scales. $\epsilon$: learning rate; $\rho$: reward modifier; $\xi$: noise; $b$: right-arrow bias.
\end{tablenotes}
\end{threeparttable}
\end{table}

\begin{table}
\centering
\begin{threeparttable}
\caption{Age and parameter estimate contrasts} \label{tab:agebetascon}
\small
```{r agebetascon, results='asis'}
knitr::kable(age_param_con_betas_table, digits = 2, escape = F, 
             col.names = colnames, format = 'latex', 
             booktabs = T)
```
\begin{tablenotes}
\footnotesize
\item Parameter contrasts were computed by subtracting the mean posterior parameter (on the constrained scales) in the Hungry/Thirsty condition from parameter estimates in the two social conditions. $\epsilon$: learning rate; $\rho$: reward modifier; $\xi$: noise; $b$: right-arrow bias.
\end{tablenotes}
\end{threeparttable}
\end{table}

### Puberty and parameters

The results for the relation between the PDS and parameter estimates follow roughly the same pattern as above (which is to be expected given the high correlation between pubertal development and age).
The parameter $\xi$ shows a negative association with PDS score, while $\rho$ is fairly flat or positive, $\epsilon$ shows a somewhat variable relation, and $b$ shows a fairly flat relation (Figure \ref{fig:pubertyparplots}).
The standardized coefficients for the relation between PDS and parameter posterior means are negative for $\xi$, and otherwise consistent with the plots (Table \ref{tab:pdsbetas}).

```{r pubertyparplots, fig.width=5.875, fig.height=4, include=F}
puberty_par_plot + ggplot2::labs(x = 'PDS mean score')
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/pubertyparplots-1.pdf}
\caption[Reinforcement learning model parameters versus puberty]{Reinforcement learning model parameters versus puberty. All best-fit lines are from generalized additive models. Grey line is fit to all data. Parameters are plotted on the unconstrained scales with possible values in $(-\infty, \infty)$. PDS = Pubertal Development Scale. $\epsilon$: learning rate; $\rho$: reward modifier; $\xi$: noise; $b$: right-arrow bias.}
\label{fig:pubertyparplots}
\end{figure}

Contrasts between learning parameters for the social versus reference conditions are all quite flat in their relation to PDS (Figure \ref{fig:pubertyparconplots}).
Standardized coefficients were all negligible or very small (Table \ref{tab:pdsbetas}).


```{r pubertyparconplots, fig.width=5.875, fig.height=4, include=F}
puberty_par_con_plot + ggplot2::labs(x = 'PDS mean score')
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/pubertyparconplots-1.pdf}
\caption[Reinforcement learning model parameter condition contrasts versus puberty]{Reinforcement learning model parameter condition contrasts versus puberty. All best-fit lines are from generalized additive models. Grey line is fit to all data. Differences are calculated using parameters transformed to be on the model scale. PDS = Pubertal Development Scale. $\epsilon$: learning rate; $\rho$: reward modifier; $\xi$: noise; $b$: right-arrow bias.}
\label{fig:pubertyparconplots}
\end{figure}


\begin{table}
\centering
\begin{threeparttable}
\caption{Pubertal development and parameter estimates} \label{tab:pdsbetas}
\small
```{r pdsbetas, results='asis'}
knitr::kable(pds_param_betas_table, digits = 2, escape = F, 
             col.names = colnames, format = 'latex', 
             booktabs = T)
```
\begin{tablenotes}
\footnotesize
\item Models were estimated using posterior mean parameters on unconstrained scales. $\epsilon$: learning rate; $\rho$: reward modifier; $\xi$: noise; $b$: right-arrow bias.
\end{tablenotes}
\end{threeparttable}
\end{table}

\begin{table}
\centering
\begin{threeparttable}
\caption{Pubertal development and parameter estimate contrasts} \label{tab:pdsbetascon}
\small
```{r pdsbetascon, results='asis'}
knitr::kable(pds_param_con_betas_table, digits = 2, escape = F, 
             col.names = colnames, format = 'latex', 
             booktabs = T)
```
\begin{tablenotes}
\footnotesize
\item Parameter contrasts were computed by subtracting the mean posterior parameter (on the constrained scales) in the Hungry/Thirsty condition from parameter estimates in the two social conditions. $\epsilon$: learning rate; $\rho$: reward modifier; $\xi$: noise; $b$: right-arrow bias.
\end{tablenotes}
\end{threeparttable}
\end{table}

# Discussion, Aim 1

Overall, the best-fitting model for learning captures the behavior of participants on the task well.
We see that the model simulations generate data that covers the full range of possible behavior, and that simulated data from the fitted parameters reproduce the average learning trajectory in each condition.
The relation between the parameters and both performance, and confidence in learning conform to our expectations based on model construction. 
Specifically, generally higher learning rates, greater inverse temperature, and lower noise all relate positively to performance and confidence.
Generally, these results can give us confidence that the model adequately capture a plausible cognitive process that gives rise to the response data.

Performance on the learning task, indexed by proportions of optimal presses, follows expected age and pubertal-development trends, with very early adolescent participants performing less well on the task.
The cognitive demands of this task are likely high as is reflected in the protracted period of learning, and so an increase on overall performance with increasing age cohort is not unexpected.
Age and development trends in parameter estimates follow this pattern as well.

Differences in performance, as well as model parameters, indicate that the two social-motive conditions enhance learning.
This is consistent with the idea that humans are motivated, especially, to learn social information.
However, estimates of these differences between conditions were fairly consistent across the entire age range, which is not what would be expected if differences between conditions in learning reflect motivations that are thought to be developing during this age range.

## Limitations

Before connecting the results of this analysis to the broader literature on reinforcement learning and social motivation, it is important to set out the limitations that must constrain interpretations of these findings.
First, learning may be obviously irrelevant to actual social goals participants have. 
That is, learning about the popularity of a computer-generated face may not be enhanced by a person's status motives because it is clear that this information is not instrumentally valuable for satisfying that motive. 
However, we did not ask participants whether they felt like they learned something that could help them in their daily lives (that is, we did not assess whether they thought there was some true, learned association between facial characteristics and either dating or social status).
So it is possible that either the irrelevance should not matter, or that many participants were motivated to learn about the faces because they thought it might be relevant information for planning future behavior.

Second, it is well known that binary choice outcomes are less reliable indicators of latent constructs than continuously measured behavior.
The proportion of variance in the parameter estimates (for learning parameters), or performance estimates, versus the variance due to uncertainty in those estimates was generally low. 
This would diminish the sensitivity of this measure to detect differences resulting from motive development at different ages.

Third, a minimal stimulus set only examines a small slice of the population of descriptors that may be relevant for mate-seeking and status motives.
Depending on the idiosyncratic characteristics of the chosen stimuli, this could produce both mean differences between conditions, as well as age correlations, or it could mask true differences and correlations.
The generalizability of any results is limited by the extent to which there is variation in any relations due to the choice of particular descriptors.
Note that randomizing the associated faces eliminates this constrained stimulus set as a possible confound, though the use of the same six faces may limit generalizability to some extent as well.

Fourth, the face-valid relevance of the descriptors to the motivational domain is not the only dimension along which the conditions differed. 
Unlike the minimally social condition, the social descriptors convey information not just about the target, but about that target's relationship to other individuals.
From the perspective of social network analysis, the descriptors "Dating" and "Looking" convey information about at least two individuals, as well as the tie(s) between them (both "Dating" and "Looking" require at least one unnamed conspecific).
The descriptors "Popular" and "Unpopular" convey information about a person's position in a broader hierarchy, and thus about the structure of ties among a much larger community.
That participants may have been sensitive to variation along this dimension is speculative, but this is at least one influence that is not related to specific social motivations that could result in salience differences between descriptor pairs and so explain the behavior of participants on this task.
Another possible dimension along which the stimuli vary may be the extent to which people believe that one can tell from facial characteristics whether someone is likely to match a descriptor.
If participants believe that there is a signal in the facial characteristics for the two social conditions, but not the minimally social condition, they may pay more attention during those trials and learn faster.
The stimuli also vary along a trait-state dimension, with Hungry/Thirsty descriptors indicating states that fluctuate on a daily basis, and the social-motive descriptors describing individual differences that fluctuate more slowly.
If this affected participant expectations, we would expect to see a higher learning rate in the conditions where the descriptor is more state-like, reflecting an expectation that one should update their beliefs more readily in the face of conflicting information.
Contrary to this pattern, we estimated higher learning rates (on average) in the social motive conditions.

Fifth, although these analyses compare a suite of models that build on the basic updating rule proposed by @rescorla1972, there are other learning models that may be relevant. 
For example, although the task was designed with prediction-error updating as the guiding principle, it might be possible to examine these data using instance based learning [@gonzalez2003a;@lejarraga2012], or a model that unifies the Rescorla-Wagner, temporal difference, and Bayesian Kalman filter approaches [@gershman2015]. 
The distinction between model-free and model-based learning strategies is also important, with evidence for developmental trends in the transition between strategies [@decker2016], but this task is not designed to examine these distinctions.

Finally, although this is a large sample that covered a broad age range, the data are cross-sectional and so it would be inappropriate to extrapolate differences across age to developmental effects within individuals [@fisher2018].
One stark example of this problem in the present research is that to infer a developmental effect in these data, one must assume that participants are exchangeable across age; that is, one must assume that the sample of young participants is more or less the same as the older participants, but just younger.
This is clearly not the case in this sample when one considers the fact that all of the older participants are attending a four-year university, whereas it is almost certainly not the case that all of the community and foster-care-involved adolescents will follow this educational path.
There is no way to gauge how much this impacts the results of these analyses.
However, it is reassuring, for example, that there does not seem to be a discontinuity between the samples in performance or parameter estimates.
Cross-sectional age differences may be a confounding source of variance for developmental effects that again may produce apparent associations or obscure true associations.

## Differences in reinforcement learning, generally, across adolescence

How do the results from this study inform our understanding of, first, reinforcement learning across adolescence and, second, social-context effects on reinforcement learning?
Almost all work on reinforcement learning in adolescence is cross-sectional, with small samples partitioned by age into groups with fewer than about 30 participants.
A few investigations exceed these sample sizes, somewhat [@davidow2016: adults = 31, adolescents = 41; @jones2014: adults = 37, adolescents = 45, children = 38; @mccormick2017: adolescents = 77].
In one notable exception, @peters2017 report on a longitudinal sample with 299 participants age 8-25 years over 3 waves yielding 736 observations.
They report results that are consistent with improvements in performance on reinforcement learning tasks across adolescence.

### Performance differences across development

The most consistent finding from this literature, and which is consistent with the present study, is that adults, or young adults, perform better than adolescents and children [@duijvenvoorde2008; @decker2015; @bos2009; @cohen2010; @christakou2013; @palminteri2016; @rosenblau2017; @peters2017; @mccormick2017].
In one study, however, adolescents performed better than adults, which was interpreted as indicating that heightened reward sensitivity may lead to better learning during adolescence [@davidow2016].
The task used was a probabilistic reinforcement learning task, just as in much of the literature indicating more optimal learning in adults compared to adolescents.
Notably, adults showed higher learning rate parameters than adolescents, but performed worse as a result.
These results are anomalous in the context of the considerable evidence for greater adult performance on standard reinforcement learning paradigms.

This consistent age finding holds across different operationalizations of learning.
Both probabilistic reinforcement [@bos2009; @cohen2010; @palminteri2016; @decker2015], and deterministic reinforcement [@duijvenvoorde2008; @peters2017] show the increase in performance with age.
Also, tasks which are more often described as risk-taking, but which involve a reinforcement learning component like the Iowa gambling task [@christakou2013], and balloon analogue risk task [@mccormick2017], also show this age trend.

Several studies did not include a measure of performance, but focus only on learning rate.
Notably, Learning rates are not linearly associated with performance when the feedback is probabilistic, but show optimal performance when a balance is struck between sensitivity to feedback and the slow accumulation of evidence about optimal behavior in a relatively stable environment.
In studies where both learning rate and performance were measured, two studies show an association with age in the same direction [with adults performing better than younger participants; @rosenblau2017; @mccormick2017].
The only study in which this relation is reversed (as mentioned above) was that reported by @davidow2016, though another study showed differently signed relations between learning rates for positive versus negative feedback [@christakou2013].

Some authors have suggested that adolescent reward sensitivity makes the developmental period of adolescence advantageous for reward learning [@davidow2016;@mccormick2017].
However, if there is indeed a peak in reward sensitivity during adolescence, it does not result in a particular advantage in most of the standard reward learning tasks reviewed above.
The evidence from the present study also supports a gradual increase in performance across the age range (roughly 12-18 years), and which is not consistent with an adolescent specific advantage driven by reward sensitivity.
In fact, adolescent reward sensitivity should be apparent in either overall performance, or in the parameter $\rho$ which modulates the magnitude of rewards.
Overall, this study represents one of the largest samples to date, second only to the cohort-sequential design of @peters2017, and presents results that greatly strengthen the evidence for an age-related increase in performance on reinforcement learning tasks.

### Effects of social manipulations

Very few studies examine social effects on reinforcement learning; those that do have relied on two approaches.
In the first approach, studies use stimuli that contain social content that is the target of learning [this is the approach taken above in the SPLT; @jones2014;@rosenblau2017].
The second approach is to situate a standard, abstract stimulus, reinforcement learning task in a social context [@decker2015;@lockwood2016] (and U/P).

The two studies that use social stimuli in the reinforcement learning task do so in a way that makes straightforward interpretation of the learning results difficult.
In one, the authors use a Pavlovian conditioning paradigm wherein the unconditioned stimulus is social in nature [@jones2014].
Specifically, on each trial, the participant sees a picture of one of three faces, which winks with the left or right eye.
The participant then indicates via button press which eye winked.
Following the response, they see a screen that indicates whether she or he receives a virtual note from the virtual peer in the picture, or whether another peer received the note.
The three faces vary by how often their wink is followed by the positive social reinforcement of receiving the note.
Reaction time for the response to the wink cue was used as the outcome for the reinforcement learning model, and accuracy (e.g., choosing 'left' when the left eye winked) was also examined.
In a sample of adults (N = 37), adolescents (N = 45), and children (N = 38), they found that wink responses were more accurate for the high-reinforcement faces (but they did not find a significant interaction with age, or report the estimated interaction coefficient), and that learning rates vary by age (with younger participants having higher learning rates).
This study indicates that social rewards by themselves may be sufficient to induce accuracy differences for conditioned cues.

However, there are several aspects of the analysis that make the association between age and learning rates difficult to interpret.
The primary issue is that the learning model is described only in broad strokes, and so the link between the expected value parameter and reaction time is not stated.
Inspecting the reported scatter plot of learning rate versus age [Figure 2, p. 691, @jones2014] reveals that many of the estimated learning rate parameters were 0, indicating that for a substantial portion of the participants, no conditioning occurred (assuming the model is well specified).
Also, with regard to the substantive conclusions assuming the data interpretation is correct, it is not possible, without a comparison with non-social-reinforcement, to interpret age differences in learning rates, or accuracy differences by reinforcement probability, as being specific to *social* reinforcers.
Notably, the results from this task, consistent with those from the SPLT, show that the impact of differential social reinforcement is not significantly different across ages.
At the very least, this null finding corroborates the findings from the SPLT that the salience, or value, added by social content does not vary systematically with respect to participant age.

Another study incorporates meaningful social information directly into the stimuli used in an instrumental learning paradigm [specifically preference ratings of objects in three broad domains: activities, fashion, and food; @rosenblau2017].
These authors use preference ratings from either three adolescents or three adults as learning targets for the adolescent (N = 24) or adult (N = 21) participants, respectively.
On each trial, the participant guessed how much the target likes the activity, fashion, or food related item, and then received feedback about the target's true score.
The authors define prediction error as the the difference between the participant's guess and the target's true preference, using this as the primary outcome of performance. 
They find that across both samples, prediction error decreases during the course of the run, with less prediction error overall for the adult group relative to the adolescent group.
They also formally model the learning process and find that the best fitting model incorporates reinforcement learning as well as information about the participant's own preferences.
The primary findings relevant to this discussion are that adults perform better than adolescents (that is, they accumulate less prediction error over the course of all trials), and this is mirrored by a higher average learning rate for adults relative to adolescents.

Although the paradigm used by @rosenblau2017 is set up superficially like more abstract instrumental learning tasks, there are some features that may preclude clear interpretations of the results.
Each item is seen only once by the participants, meaning that any learning that occurs requires generalization from one item to other items. 
In other words, learning on the task requires that there is an inherent structure to the targets' preferences that can be learned.
This is, of course, trivially true in that each target has a mean rating that could be learned.
Though the authors present several non-significant _p_-values to support the equivalence of the adolescent and adult preference profiles, the sample size is quite under-powered to detect differences, and it is not clear what size differences might matter with respect to learning and prediction error differences across age-groups.
It _is_ clear that more consistent ratings by the target (whatever the assumed structure of relation among item preferences) would lead to better performance. 
It is also clear that the similarity of a target's and a participant's rating would influence the prediction error and estimated learning parameters.
The effect of similarity is included in the learning model, and does improve the model fit, indicating that participants may have been using their own preferences when guessing target preferences.
Conclusions about age-group differences in instrumental learning of social information are obscured by the idiosyncrasies in the task design mentioned above.
However, the finding of better adult performance is in line with the wider literature both when the content of learning is social, or non-social.

Two studies take the second approach of examining the effect of social context or cues on learning, and while they are less directly relevant to the present research, they are worth considering because they demonstrate that different social cues can affect learning.
@lockwood2016 use a probabilistic reinforcement learning paradigm, manipulating whether the participants (N = 31 males, age 19-32 years) gain rewards for themselves, a friend, or no-one (that is, the points are displayed but do not accrue to anyone).
They find that performance and learning rate is higher in the self condition than in the other two conditions.
@decker2015 use a standard probabilistic reinforcement task, but add a cue set for which participants are given information about what the best choice is.
They find that adults (N = 26) are more sensitive to this information than adolescents (N = 31). 
When the instruction is erroneous, this incurs a penalty for adult performance relative to adolescents.

Across social reinforcement learning studies, the tentative conclusion is that social information or reinforcement results in similar developmental patterns in performance as does non-social reinforcement.
It does seem possible, though the evidence is limited, that there could be an adolescent-specific advantage with regard to performance in the face of social-misdirection.
However, there seems to be scant evidence for any particular adolescent sensitivity to social versus non-social stimulus content, or for advantages (or disadvantages) driven specifically by developmental sensitivity to rewards.

## Conclusions

The results from the present study add weight to the evidence for better overall performance on reinforcement learning tasks for older participants in the age range from early to late adolescence and young adulthood.
We also find, consistent with prior literature, a positive correlation between performance and learning rate, though there is some indication in this sample that there is a non-linearity such that at some point, higher learning rates impede performance. 
This is the expected behavior of the learning model with respect to probabilistic feedback, and future work should ensure that this possibility is accounted for, or else risk misinterpreting linear correlations between learning rates and other measures.
We also see a positive correlation between the inverse temperature parameter, $\rho$, that governs the magnitude of rewards (versus no-reward, in this case) and performance.
In the mate-seeking and status conditions where performance is best, the learning rate, $\epsilon$, is indeed higher than in the minimally social condition. 
Unsurprisingly, the noise parameter, $\xi$, which estimates the degree of random responding across the entire run, is also monotonically related to performance.
The increased performance in the two social conditions is also reflected (though much less robustly) in this parameter being somewhat lower than in the reference condition.

There is no relation of age or PDS with the social condition boost in learning performance, or with the learning parameters for those conditions relative to the reference condition.
In other words, the enhancement of learning due to the increased salience of the social descriptors does not vary consistently with age or pubertal status.
While this is consistent with a small number of prior studies, the present study demonstrates this phenomenon using a  straightforward design, and a much larger sample size than in previous studies.
In light of the evidence upon which the social reorientation hypothesis is based, there are several possible explanations.
In the early part of this age range (12 years), information about dating and social status may already be clearly important, and so salience differences may already be at ceiling with respect to task difficulty.
As mentioned in the limitations, above, it may also be the case that although the social conditions are somewhat more interesting, salience is not affected by motivation in the relevant motive domains and so is not sensitive to developmental changes.
Of course, it is possible that this null effect truly does reflect an underlying, age-stable motivational orientation toward information about dating and social status that is not affected by the developmental-stage-specific neurobiological changes in motivational systems, as proposed by the social reorientation hypothesis.
If this is the case, it would be somewhat inconsistent with the hypothesis that underlying motivational changes, rather than changes in the social milieux, are predominantly responsible for behavioral changes during adolescence.


<!--stackedit_data:
eyJoaXN0b3J5IjpbLTIxNDM3NDY2NDldfQ==
-->
<!--stackedit_data:
eyJoaXN0b3J5IjpbNDMyNTc3MDIwLDE5Nzk4MjMwNTEsNDMyNT
c3MDIwXX0=
-->