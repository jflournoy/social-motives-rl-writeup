---
header-includes:
  - \usepackage[para,online,flushleft]{threeparttable}
  - \usepackage{wrapfig}
  - \usepackage[singlelinecheck=false]{caption}
  - \captionsetup[subfigure]{singlelinecheck=on, labelfont=normalfont}
  - \captionsetup[figure]{labelfont=it}
output: 
  pdf_document:
    keep_tex: yes
bibliography: "/home/jflournoy/code_new/social-motives-rl-writeup/dissertation.bib"
csl: "/home/jflournoy/Rlibs/probly/bib/apa-old-doi-prefix.csl"
---

```{r setupch3, include=FALSE}
knitr::opts_chunk$set(fig.path = 'figures/', echo = F, warning = F, error = F, message = F)
library(probly)
load('rda/test-simulated-data.rda')
```


# Background

A substantial body of work on the relation between learning and attention indicates that stimulus salience, motivational relevance, and learning rate.
In laying out a programmatic approach to learning and attention, @mackintosh1975a [p. 294] concludes that the idea that learning rates are different depending on the stimulus is "formally equivalent to one of the main tenets of two-stage, attentional theories of learning, namely, the assumption that the probability of attending to a stimulus determines the probability of learning about that stimulus."
@grossberg1975 summarizes literature indicating that if two cues are paired with an unconditioned stimulus, the more salient cue will be conditioned more quickly to the extent that it may create a blocking effect against the conditioning of the less salient cue.
More recently, @denton2006 demonstrated in humans that the blocking effect is modulated by salience. 
Blocking refers to the phenomenon that when a new stimulus is conditioned in conjunction with an older stimulus that has already been associated with an outcome, the new stimulus builds up a less strong association with the outcome.
Though many models have been developed to account for this phenomenon, one explanation is that the new stimulus provides no new information for predicting the outcome (which is already perfectly predicted by the prior associated stimulus), and so it is not learned [see @shanks2010 for an overview].
In this study, using cues of colored dots and modulating salience by the density of dots, the authors showed that it is harder to block a new cue if that new cue is more salient (higher dot density) than the already conditioned cue.

Such attentional effects on learning may not be mere spandrels of our evolved learning mechanisms, but a key feature that helps learning beings learn quickly in contingent environments.

# Method

## Modeling approach

The focus of this dissertation is on describing and estimating differences in learning that is proposed to be related to differences in motives that develop during adolescence.
The goal of such estimation is to provide reliable information about the magnitude and sign of relations between observed phenomena, as well as about the uncertainty of that information.
A Bayesian approach provides a robust framework for specifying and estimating hierarchical and nonlinear models with many parameters while constraining inferences in a way that reduces the rate of making incorrect claims with confidence [@GelmanPowerCalculationsAssessing2014;@gelman_why_2012].
These are key concerns for the current work for two reasons.
First, convergence of reinforcement learning  model can be difficult to achieve, and Bayesian estimation helps by allowing one to constrain parameter values for these models in a principled and intuitive way using parametric prior distributions.
Second, in contrast to a confirmatory experiment, this dissertation seeks to explore relations between a number of theoretically related constructs; as such, the hierarchical Bayesian approach helps constrain estimates in ways that increase their efficiency [@gelman_why_2012].


## A model for reinforcement learning

In the context of this task, where the relation between the optimal response and the stimulus is constant, a simple model of the degree of learning could rely on a simple proportion of optimal responses $P_{ok}$ for each condition $k$.
The test of the hypothesis of the effect of framing would then be the difference between conditions in $P_o$. 
This simple model sacrifice precision for simplicity, and so I will be modeling the data using a reinforcement learning model with several parameters that can account for deviations from a strict Rescorla-Wagner (RW) process.
This increases the number of possible comparisons I am able to make between conditions, which may generate useful information about how motive-domain framing affects the learning process (as modeled, of course), but which also increases the complexity of patterns between conditions and parameters that must be interpreted.
It will be helpful to keep in mind that the framing can only be said to potentiate learning if, regardless of its affect on any model parameters, it does not result in higher proportions of optimal responding.

In this section, I simulate data as expected under the Rescorla-Wagner model implemented by @ahn2017 in their go-no-go model 2. 
Their original model handles binary decisions (button-press or no button-press) in response to four different cues. 
However, the form of the learning algorithm is generalizable to other binary choices in response to cues. 
In the case of the Social Probabilistic Learning Task (SPLT), participants are presented with a face (the cue), and must decide to press the left key or the right key. 
They are rewarded probabilistically such that for each cue, one or the other of the response options has an 80% chance of providing reinforcement. 
The go-no-go models used by @ahn2017 were derived from work by @guitart-masip2012. 
Their most flexible reinforcement learning model generates the probability of an action for each trial via N parameters: the learning rate, $\epsilon$, the effective size of reinforcement, $\rho$, a static bias parameter, $b$, an irreducible noise parameter, $\xi$, and a Pavlovian learning parameter, $\pi$.
In the SPLT, trial feedback does not vary by valence (responses result in reward, or no reward, but never punishment), so I use the model that does not include this Pavlovian component. 

## Reinforcement learning model for the SPLT

The model for an individual $j$'s probability of pressing the right arrow key on trial $t$ given that stimulus $s_{t}$ is presented, $P(a_{\rightarrow t} | s_{t})_{t}$, is determined by a logistic transformation of the action weight for pressing the right arrow key minus the action weight for pressing the left arrow key. 
This probability is then adjusted by a noise parameter, $0 \leq\xi_{jk}\leq1$ for each participant $j$ in condition $k$.
The noise parameter modulates the degree to which responses are non-systematic. 
When $\xi$ is 1, $P_{it} = .5$, and because each individual has a unique noise parameter for each condition, I am able to account for participants who do not learn during the task, or in a particular condition.
The full equation is:

$$
P(a_{\rightarrow t} | s_{t})_{t} = 
\text{logit}^{-1}\big(W(a_{\rightarrow t}| s_{t}) - W(a_{\leftarrow t}| s_{t})\big)\cdot(1-\xi_{jk}) + \small\frac{\xi_{jk}}{2}.
$$

The action weight is determined by a Rescorla-Wagner (RW) updating function $Q$, $W_{t}(a,s) = Q_{t}(a, s)$.
Although this may seem like a redundant step, I specify it this way to be consistent with @guitart-masip2012, and to illustrate the possibility that another parameter could impact the action weight separately from $Q$.
The function $Q$ encodes instrumental learning and is governed by the individual's learning rate for that condition, $\epsilon_{jk}$, and a scaling parameter $\rho_{jk}$ that scales the effective size of the possible rewards $r_t \in \{0, 1, 5\}$:

$$
Q_{t}(a_t, s_t) = Q_{t-1}(a_t, s_t) + \epsilon_{jk}\big(\rho_{jk}r_t - Q_{t-1}(a_t, s_t)\big)
$$

### Hierarchical Parameters

Each parameter ($\epsilon, \rho, b, \xi$) varies by condition $k \in 1:K$, and by participant $j \in 1:J$ nested in sample $m \in 1:M$. 
The structure of the hierarchical part of the model is the same for each parameter, so the following description for $\epsilon$ will serve as a description for all of the parameters.
For each individual $j$, $\beta_{\epsilon j}$ is a $K$-element row of coefficients for parameter $\epsilon$ for each condition:

$$
\beta_{\epsilon j} \sim \mathcal{N}(\delta_{\epsilon mm[j]}, \Sigma_{\epsilon})
$$
where $\delta_{\epsilon mm[j]}$ is a column of $K$ means for individual $j$'s sample $M$, as indexed in the vector $mm$, and $\Sigma_{\epsilon}$ is a $K\times K$ matrix of the covariance of individual coefficients between conditions.

Finally, across all $M$ samples, the means for each condition k are distributed such that: 

$$
\delta_{\epsilon k} \sim \mathcal{N}(\mu_{\epsilon k}, \sigma_\epsilon)
$$

where $\mu_{\epsilon k}$ is the population mean for parameter $\epsilon$ in condition $k$, and $\sigma$ is a slightly regularizing scale parameter for these means across all conditions and samples. The priors for these final parameters are:

$$
\begin{split}
\mu_\epsilon &\sim \mathcal{N}(0, 5)\\
\sigma_\epsilon &\sim \text{exponential(1)}.
\end{split}
$$

Note that in practice all parameter estimates were practically identical whether or not nesting within sample was modeled and so I describe only the model without nesting.
I maintain the description above to illustrate for the reader that it is at least practically possible to account for another level of hierarchy.
The model specification for both sets of models is available in the acompanying package.

## Simulating data

Before modeling the task data, I will confirm that this model can recover known parameters from simulated data.
Using RStan [version `r packageVersion('rstan')`; @standevelopmentteam2018], I simulate 100 data sets based on the structure of the sample data, using the same number of participants per sample (see the section on [descriptive statistics](descriptive-statistics.html), as well as precisely the same task structure. 
For this aim, it is important to be able to recover all $\mu_{\theta k}$ for $\theta \in \{\epsilon,\rho,b,\xi\}$ and $k \in \{1,2,3\}$, where 1 = Hungry/Thirsty, 2 = Popular/Unpopular, and 3 = Dating/Looking. Those parameters that account for idiosyncratic deviation from RW-expected behavior ($b,\xi$) will not vary by condition. Based on interactive simulation ([here](https://jflournoy.shinyapps.io/rw_model/)), reasonable parameter values for the control condition might be $\mu_\epsilon = -1.65$ and $\mu_\rho = -0.3$ [^1].

[^1]: Note that these are the _raw_ parameter values which are transformed such that $\epsilon^\prime \in [0,1]$ and $\rho^\prime \in [0,\infty)$. Similar to logistic regression, estimating the parameters on a scale the is not resticted improves estimation.

One early indication that a model may not be well suited to a problem is that when generating from the prior distribution, datasets are produced that either do not adequately cover the range of reasonable values, or that cover ranges that are implausible [@gabry2017]. 
The simulated data do generally cover the range of the actual data when we look just at the proportion of optimal presses over time (Figure \ref{fig:simdatcoverage}, and importantly do not show implausible behavior (all mass around extreme values like 0, 1, or .5).

```{r simdatcoverage, fig.width=5.875, fig.height=4, include=F}
print(nosmooth_multi_plot)
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/simdatcoverage-1.pdf}
\caption[Model-simulated task data]{Model-simulated task data. Each point is the mean of optimal presses on that trial, for the indicated condition, from 1 of 100 simulated data sets using just the model prior distributions. The red line is at .5, corresponding to random responding. It is apparent that the model priors allow coverage of the entire range of realistic responses.}
\label{fig:simdatcoverage}
\end{figure}

More detailed descriptions of the simulated date broken out per-simulation are available on the project's [github webpage](https://jflournoy.github.io/probly/).

The priors also generate reasonable ranges for the model parameters across these 100 simulations. 
Notably, the mass of the prior distributions is distributed across the full range of reasonable values at each level.
This results ultimately in a prior  distribution over the final probability of choosing the word on the right-hand side of the screen. These distributions cover the full range, with most mass around the null value of the final probability = .5 for choosing the left or right option.
If the data does not overwhelm the prior distribution, we can be assured that the prior is not biasing the estimate away from random responding.

FIGURES WITH DRAWS FROM PRIORS HERE

## Recovery of population parameters

After generating these simulated data sets and known parameter values, the model was then fit to these simulated data to evaluate its ability to revover the parameters. 
The mode was fit using 4 chains with 1000 warmup iterations and 500 sampling iterations per chain. 
An example from one simulation of estimated posterior densities for the final probability of a participant choosing the right-hand label shows that nearly all estimates capture the underlying generating parameter (Figure \ref{fig:pRfinalplot}).



```{r pRfinalplot, fig.width=5.875, fig.height=4, include=F}
ggplot2::theme_set(ggplot2::theme_minimal())
do.call(gridExtra::grid.arrange, pR_final_plots)
```

&nbsp;

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/pRfinalplot-1.pdf}
\caption[Correspondence of simulation generated and estimated behavior]{Correspondence of simulation generated and estimated behavior. The X-axis indexes the simulation-generated final-trial right-hand button-press probability ($P_\text{r-final}$), and the Y-axis indexes the estimated posterior median $P_\text{r-final}$. Whiskers indicate the posterior 2.5\% and 97.5\% quantiles.}
\label{fig:pRfinalplot}
\end{figure}

To examine the performance of all of the simulations, after the posteriors for each simulation estimate were sampled, the empirical cummulative density function was composed for the distribution of each parameter. 
The cumulative density for the generating value (from the simulation) was then found. 
This procedure is the same as finding the _p_-value for a test statistic using the probability density function for the relevant distribution.
If the posterior is a reasonable estimate of the generating parameter, then the generating parameter should be a random draw from that posterior. 
As such, the distribution of the _p_-value of the generating parameters (in relation to the posteriors) should be uniform. 

PLOTS SHOWING UNIFORM DISTRIBUTION HERE

## Target model and estimation of sample parameters

The model was fit in RStan [version `r packageVersion('rstan')`; @standevelopmentteam2018] using R [version `r paste(version$major,version$minor, sep = '.')`; @rcoreteam2018].


# Results

```{r}
rm(list = ls())
load('rda/fit-model-to-participant-data.rda')
```

```{r}
grid_arrange_shared_legend <- function(..., ncol = 1, widths) {
  plots <- list(...)
  g <- ggplot2::ggplotGrob(plots[[1]] + 
                             ggplot2::theme(legend.position="bottom")+
                             ggplot2::guides(linetype = ggplot2::guide_legend(override.aes=list(fill=NA)),
                                             shape = ggplot2::guide_legend(override.aes=list(alpha=.5))))$grobs
  legend <- g[[which(sapply(g, function(x) x$name) == "guide-box")]]
  lheight <- sum(legend$height)
  gridExtra::grid.arrange(
    do.call(gridExtra::arrangeGrob, c(lapply(plots, function(x)
      x + ggplot2::theme(legend.position="none")), list(ncol = ncol, widths = widths))),
    legend,
    nrow = 2,
    heights = grid::unit.c(ggplot2::unit(1, "npc") - lheight, lheight))
}
```

## Descriptive data

- Describe behavior across the run in each condition based on non-parameteric plots based on trial-by-trial means

```{r trialaverages, fig.width=5.875, fig.height=4, include=F}
ggplot2::theme_set(ggplot2::theme_minimal())
avg_per_sample_plot2 <- avg_per_sample_plot + 
  ggplot2::facet_wrap(~sample, nrow = 2, 
                      labeller = ggplot2::label_wrap_gen(width = 20))

grid_arrange_shared_legend(avg_per_sample_plot2, avg_across_samples, ncol = 2, widths = c(1.3,1))
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/trialaverages-1.pdf}
\caption[Average optimal behaviour over trial]{Average optimal behaviour over trial. Each point is the average across participants for that trial for the indicated condition. Best fit lines and confidence bands are estimated using generalized additive models and are for illustrative purposes only.}
\label{fig:trialaverages}
\end{figure}

- Define mean final probability of making optimal press, $P_{O}$, as the mean probability of optimal press from the last half of the run.
- This is correlated at _r_ = .96 with a simple logistic regression model and _r_ = ?? with reward learning model.

## Model estimated parameters

### Validation of parameters

- Comparison to observed optimal presses $P_{O}$
  - Figure \ref{fig:parametersvbehavior}
  - The relations illustrated in this figure demonstrate that the models relation to the observed behavior is in line with expected relations based on simulation where, for any given value of $\rho$ in this range, there is a sweet-spot for $\epsilon$. 
  - This is due to learning that is too slow (low $\epsilon$, across all $\rho$), overweighting early, but "wrong" evidence (high $\rho$, lower $\epsilon$), or overweighting contradictory evidence at any point in the trial (high $\epsilon$, across all $\rho$).
  - The high noise parameter accounts for the behavior of participants who learn less during the task than would be expected by their learning rate parameters alone.
  
```{r parametersvbehavior, fig.width=5.875, fig.height=4, include=F}
allparameter_plot <- ggplot2::ggplot(lowfi_learning_df,
                ggplot2::aes(x = ep_mean,
                             y = qnorm(p_opt),
                             group = xi_mean_bin,
                             color = xi_mean)) + 
    ggplot2::geom_hline(yintercept = qnorm(.8), alpha = .5) + 
    ggplot2::geom_hline(yintercept = qnorm(.5), alpha = .5, color = 'blue') + 
    ggplot2::geom_point(alpha = .35) + 
    ggplot2::geom_smooth(method = 'gam', formula = y ~ s(x, fx = T, k = 3), 
                         alpha = .2, color = 'black', size = .5,
                         ggplot2::aes(linetype = xi_mean_bin)) + 
    ggplot2::scale_color_gradient(low = 'red', high = 'blue') + 
    ggplot2::facet_wrap(~rho_mean_bin) + 
    # ggplot2::theme(strip.text = element_blank()) + 
    ggplot2::coord_cartesian(ylim = c(qnorm(.40), qnorm(.998))) + 
    ggplot2::scale_y_continuous(breaks = qnorm(c(.5, .8, .998)), labels = c(.5, .8, .995)) +
    ggplot2::scale_x_continuous(breaks = qnorm(c(.01, .1, .4)), labels = c(.01, .1, .4)) + 
    ggplot2::labs(x = expression(paste('Median posterior ',beta[epsilon])),
                  y = 'Probability of choosing optimal lable',
                  caption = expression(paste('Facet labels are ranges for median posterior ', beta[rho])),
                  color = expression(paste('Median ', beta[xi])),
                  linetype = expression(paste('Median ', beta[xi], ' range')))
allparameter_plot
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/parametersvbehavior-1.pdf}
\caption[Run-end optimal press behavior and RW learning parameters]{Run-end optimal press behavior and RW learning parameters. Each point is a data from one participant. As the parameter $\epsilon$ increases (X-axis), probability of making an optimal choice increases to a maximum and then decreases. Facets bin increasing values of $\rho$ which also indicate increasing optimal choice. However, as expected, higher values of the noise parameter, $\xi$ (dotted line) suppress the associations between optimal choice behavior and the other two parameters.}
\label{fig:parametersvbehavior}
\end{figure}
  
- Comparison to confidence ratings
  - Confidence ratings allow another point of comparison for model parameters.
  - After each 48 trials, participants were asked to rate how confident they were, overall, that they knew which word was the best choice for each face.
  - Figure \ref{fig:confidencevparameters} shows the relations between confidence ratings at the end of all trials and the model estimated parameters.
  - The clear relations here may merely imply that the participants are aware of their behavior, and the model parameters show adequately systematic relations to that behavior such that they are also correlated with confidence ratings.
  - It is not clear whether the especially strong relation between the reward sensitivity parameter, $\rho$, is meaningful.
    - This may simply reflect that for a given learning rate, higher $\rho$ and lower $\xi$ reflect a quicker accumulation of action weight, or in other words, knowledge about the optimal response.
    - This point will be revisted later when comparing self-report scales to parameter estimates.

```{r confidencevparameters, fig.width=5.875, fig.height=4.1, include=F}
parameter_lookup <- c(
  ep = 'epsilon',
  rho = 'rho',
  xi = 'xi'
)

confidence_parameter_plot +
  ggplot2::facet_grid(condition ~ parameter, scales = 'free_x', 
                      labeller = ggplot2::labeller(
                        parameter = ggplot2::as_labeller(parameter_lookup,
                                                         default = ggplot2::label_parsed)))
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/confidencevparameters-1.pdf}
\caption[Confidence in learning and RW learning parameters]{Confidence in learning and RW learning parameters. Each point is the confidence rating for a single participant at the end of all trials (and because each participant has only one rating, a participant's value on the Y-axis is the same across all panels). A clear association between $\rho$ and confidence, and $\xi$ and confidence can be seen.}
\label{fig:confidencevparameters}
\end{figure}

## Population-level parameters

```{r}
lowfi_ht_dl_t <- PairedData::yuen.t.test(
  lowfi_df$bin_5_to_end[lowfi_df$condition == 'Dating/Looking'], 
  lowfi_df$bin_5_to_end[lowfi_df$condition == 'Hungry/Thirsty'], 
  paired = T)
apa_lowfi_ht_dl_t <- paste0('*t*(', lowfi_ht_dl_t$parameter, ') = ', round(lowfi_ht_dl_t$statistic,2), 
               ', *p* = ', round(lowfi_ht_dl_t$p.value, 3), 
               ', $\\bar{D}$ = ', round(lowfi_ht_dl_t$estimate,3), 
               ' [', paste(round(lowfi_ht_dl_t$conf.int,3), collapse = ','), ']')

lowfi_ht_pu_t <- PairedData::yuen.t.test(
  lowfi_df$bin_5_to_end[lowfi_df$condition == 'Popular/Unpopular'],
  lowfi_df$bin_5_to_end[lowfi_df$condition == 'Hungry/Thirsty'], 
  paired = T)
apa_lowfi_ht_pu_t <- paste0('*t*(', lowfi_ht_pu_t$parameter, ') = ', round(lowfi_ht_pu_t$statistic,2), 
               ', *p* = ', round(lowfi_ht_pu_t$p.value, 5), 
               ', $\\bar{D}$ = ', round(lowfi_ht_pu_t$estimate,3), 
               ' [', paste(round(lowfi_ht_pu_t$conf.int,3), collapse = ','), ']')
```

Overall, learning was potentiated in the Dating/Looking, and Popular/Unpopular conditions.
Paired sample Yuen *t* tests, which are robust to non-normality [@yuen1974], reject the null of no difference between the two conditions of interest and the control condition (Dating/Looking: `r apa_lowfi_ht_dl_t`; Popular/Unpopular: `r apa_lowfi_ht_pu_t`).
This difference is also reflected in the parameter estimates (Figures \ref{fig:epsdiff}, \ref{fig:rhodiff}, \ref{fig:xidiff}).


```{r epsdiff, fig.width=3.5, fig.height=3, include=F}
epsilon_difference_plot
```

\begin{figure}
\centering
\captionsetup{width=3.25in}
\includegraphics{figures/epsdiff-1.pdf}
\caption[Condition contrasts for $\epsilon$]{Condition contrasts for $\epsilon$. Subscript number denotes condition. Condition 1 is Hungry/Thirsty, Condition 2 is Dating/Looking, Condition 3 is Popular/Unpopular. Shaded region is 95\% credible region, and tails extend to 99.5\% credible region.}
\label{fig:epsdiff}
\end{figure}

```{r rhodiff, fig.width=3.5, fig.height=3, include=F}
rho_difference_plot + 
  ggplot2::coord_cartesian(xlim = c(-1.5, .4))
```

\begin{figure}
\centering
\captionsetup{width=3.25in}
\includegraphics{figures/rhodiff-1.pdf}
\caption[Condition contrasts for $\rho$]{Condition contrasts for $\rho$. Subscript number denotes condition. Condition 1 is Hungry/Thirsty, Condition 2 is Dating/Looking, Condition 3 is Popular/Unpopular. Shaded region is 95\% credible region, and tails extend to 99.5\% credible region.}
\label{fig:rhodiff}
\end{figure}

```{r xidiff, fig.width=3.5, fig.height=3, include=F}
xi_difference_plot
```

\begin{figure}
\centering
\captionsetup{width=3.25in}
\includegraphics{figures/xidiff-1.pdf}
\caption[Condition contrasts for $\xi$]{Condition contrasts for $\xi$. Subscript number denotes condition. Condition 1 is Hungry/Thirsty, Condition 2 is Dating/Looking, Condition 3 is Popular/Unpopular. Shaded region is 95\% credible region, and tails extend to 99.5\% credible region.}
\label{fig:xidiff}
\end{figure}

PREDICTED RESPONSE BEHAVIOR BASED ON MEAN PARAMETERS GOES HERE

## Age, puberty, and learning

### Mean optimal presses

- Age and overall performance
- Puberty and overall performance

```{r poptageplot, fig.width=5.875, fig.height=4, include=F}
p_opt_age_plot
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/poptageplot-1.pdf}
\caption[poptageplot]{poptageplot}
\label{fig:poptageplot}
\end{figure}

```{r poptpdsplot, fig.width=5.875, fig.height=4, include=F}
p_opt_pds_plot
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/poptpdsplot-1.pdf}
\caption[poptpdsplot]{poptpdsplot}
\label{fig:poptpdsplot}
\end{figure}

```{r poptdiffageplot, fig.width=5.875, fig.height=4, include=F}
p_opt_diff_age_plot
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/poptdiffageplot-1.pdf}
\caption[poptdiffageplot]{poptdiffageplot}
\label{fig:poptdiffageplot}
\end{figure}

```{r poptdiffpdsplot, fig.width=5.875, fig.height=4, include=F}
p_opt_diff_pds_plot
```

\begin{figure}
\centering
\captionsetup{width=5.875in}
\includegraphics{figures/poptdiffpdsplot-1.pdf}
\caption[poptdiffpdsplot]{poptdiffpdsplot}
\label{fig:poptdiffpdsplot}
\end{figure}

- Age and parameters
- Puberty and parameters

# Discussion, Aim 1

- The model captures learning behavior well
- There is an expected and reasonable relation between model parameters and performance
- There is an expected and reasonable relation between model parameters and confidence
- Age and PDS trends indicate that in very early adolescence, participants do less well on the task
  - The cognitive demands of this task are somewhat high, and so an overall increase into middle adolescence is sensible
- Age and development trends in parameter estimates ...
- Salience matters, but this effect is stable across participants of different 

## Prior literature

- extensive use of this task
  - focus on reward
  - exploration of social aspects
- mixed literature
  - performance not consistently better in adults versus adolescents
  - task compentence does increase into middle adolescence
    - likely ef related
  - learning rates not consistently higher or lower in adults versus adolescents
  

-----

